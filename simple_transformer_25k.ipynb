{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "simple transformer_25k.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R53kjrYGpSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a1621ae-1a8d-4f13-93ee-dcd904dbbd01"
      },
      "source": [
        "!git clone https://github.com/moaaztaha/Arabic-English-Translation-Transformers"
      ],
      "id": "0R53kjrYGpSc",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Arabic-English-Translation-Transformers'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 24 (delta 0), reused 24 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9e97fa1"
      },
      "source": [
        "# modules\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "id": "e9e97fa1",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1710411f"
      },
      "source": [
        "### Data Preprocessing "
      ],
      "id": "1710411f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RNDMX9cizGW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a5babae5-fd8f-4ee1-f5be-f0ac0e2250ed"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/Arabic-English-Translation-Transformers/ara_eng.txt\",delimiter=\"\\t\",names=[\"eng\",\"ar\"])\n",
        "df.head()"
      ],
      "id": "1RNDMX9cizGW",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>ar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>مرحبًا.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>اركض!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Help!</td>\n",
              "      <td>النجدة!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jump!</td>\n",
              "      <td>اقفز!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>قف!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     eng       ar\n",
              "0    Hi.  مرحبًا.\n",
              "1   Run!    اركض!\n",
              "2  Help!  النجدة!\n",
              "3  Jump!    اقفز!\n",
              "4  Stop!      قف!"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4aku8mEi7Xg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f3cf83-7e4f-46c2-c60a-2339a8b0923d"
      },
      "source": [
        "for i in range(df.shape[0]):\n",
        "  if len(df.eng.iloc[-i].split()) > 150:\n",
        "    print(\"big\")"
      ],
      "id": "m4aku8mEi7Xg",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "big\n",
            "big\n",
            "big\n",
            "big\n",
            "big\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be905b2c"
      },
      "source": [
        "text_pairs = []\n",
        "for idx, row in df.iterrows():\n",
        "    eng, ar = row['eng'], row['ar']\n",
        "    ar = \"[start] \" + ar + \" [end]\"\n",
        "    text_pairs.append((eng, ar))"
      ],
      "id": "be905b2c",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "296e4594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83626337-2eef-4dfd-91c3-77b5b13455ec"
      },
      "source": [
        "for _ in range(2):\n",
        "    print(random.choice(text_pairs))"
      ],
      "id": "296e4594",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('since the government of kuwait has ramped up efforts to control online speech and activity according to human rights watch twitter user musab shamsah was sentenced to five years in prison for a tweet that commented on theological differences between sunni and shia muslims.', '[start] منذ عام ٢٠١٢ لا تالو الحكومة الكويتية جهدا في سبيل التحكم في الخطاب والنشاط الالكتروني نشرت منظمة هيومان رايتس ووتش خبرا عن حبس المغرد مصعب شمساه خمس سنوات على تغريدة مسيية اثناء نقاش بين سنة وشيعة [end]')\n",
            "('His help is indispensable to us.', '[start] لا غِنى لنا عن مساعدته. [end]')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1283f6f"
      },
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) -  num_val_samples\n",
        "train_pairs = text_pairs[: num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples: num_train_samples + num_val_samples]"
      ],
      "id": "c1283f6f",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7a1f8cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad71718-9a80-400a-de91-62478ce457d9"
      },
      "source": [
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")"
      ],
      "id": "a7a1f8cd",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24638 total pairs\n",
            "20943 training pairs\n",
            "3695 validation pairs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5f6d84e"
      },
      "source": [
        "#### Vectorizing the text data "
      ],
      "id": "d5f6d84e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "487ed66f"
      },
      "source": [
        "strip_chars = string.punctuation\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "\n",
        "vocab_size = 50000\n",
        "sequence_length = 150\n",
        "batch_size = 128\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    return tf.strings.regex_replace(input_string, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "            max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_length)\n",
        "\n",
        "ar_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization)\n",
        "\n",
        "eng_texts = [pair[0] for pair in text_pairs]\n",
        "ar_texts = [pair[1] for pair in text_pairs]\n",
        "eng_vectorization.adapt(eng_texts)\n",
        "ar_vectorization.adapt(ar_texts)"
      ],
      "id": "487ed66f",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5qiqjOWdVz1"
      },
      "source": [
        "def format_dataset(eng, ar):\n",
        "    eng = eng_vectorization(eng)\n",
        "    ar = ar_vectorization(ar)\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": ar[:, :-1],}, ar[:, 1:])\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, ar_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    ar_texts = list(ar_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ar_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()"
      ],
      "id": "V5qiqjOWdVz1",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a3ed140"
      },
      "source": [
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "id": "7a3ed140",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3902789f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9544f273-b777-468c-e21a-a976b7d33f3f"
      },
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "id": "3902789f",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (128, 150)\n",
            "inputs[\"decoder_inputs\"].shape: (128, 150)\n",
            "targets.shape: (128, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fa0936c"
      },
      "source": [
        "### Building the Model "
      ],
      "id": "4fa0936c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3baf452"
      },
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "      config = super().get_config().copy()\n",
        "      config.update({\n",
        "          'embed_dim': self.embed_dim,\n",
        "          'dense_dim': self.dense_dim,\n",
        "          'num_heads': self.num_heads,\n",
        "      })\n",
        "      return config\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "      \n",
        "    def get_config(self):\n",
        "\n",
        "      config = super().get_config().copy()\n",
        "      config.update({\n",
        "      'sequence_length': self.sequence_length,\n",
        "      'vocab_size': self.vocab_size,\n",
        "      'embed_dim': self.embed_dim,\n",
        "      })\n",
        "      return config\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "      config = super().get_config().copy()\n",
        "      config.update({\n",
        "      'embed_dim': self.embed_dim,\n",
        "      'latent_dim': self.latent_dim,\n",
        "      'num_heads': self.num_heads,\n",
        "      })\n",
        "      return config\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ],
      "id": "b3baf452",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04c57e1e"
      },
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "id": "04c57e1e",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt9sp6Yrb4pE"
      },
      "source": [
        "googledrive_path = '/content/drive/MyDrive/Transformers/voc25k/'"
      ],
      "id": "vt9sp6Yrb4pE",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqmaEQ94kyB9"
      },
      "source": [
        "from keras import callbacks\n",
        "early_stopping_cb = callbacks.EarlyStopping(monitor='val_accuracy', patience=4, verbose=True)\n",
        "checkpoint_cb = callbacks.ModelCheckpoint(googledrive_path+'weights_rmsprop.ckpt', monitor='val_accuracy', save_weights_only=True,verbose=True, save_best_only=True)\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=googledrive_path+\"logs\")\n",
        "cbs = [early_stopping_cb, checkpoint_cb, tensorboard_callback]"
      ],
      "id": "wqmaEQ94kyB9",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H50DkdfyLyqt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37df70dc-1f7c-42dd-c6d2-186825f4ac31"
      },
      "source": [
        "epochs = 30  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=cbs)"
      ],
      "id": "H50DkdfyLyqt",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "positional_embedding_6 (Positio (None, None, 256)    6438400     encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder_3 (Transfor (None, None, 256)    3155456     positional_embedding_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "model_7 (Functional)            (None, None, 25000)  18122920    decoder_inputs[0][0]             \n",
            "                                                                 transformer_encoder_3[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 27,716,776\n",
            "Trainable params: 27,716,776\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "164/164 [==============================] - 154s 919ms/step - loss: 0.8427 - accuracy: 0.1439 - val_loss: 0.8016 - val_accuracy: 0.1734\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.17342, saving model to /content/drive/MyDrive/Transformers/voc25k/weights_rmsprop.ckpt\n",
            "Epoch 2/30\n",
            "164/164 [==============================] - 149s 907ms/step - loss: 0.7945 - accuracy: 0.1786 - val_loss: 0.7710 - val_accuracy: 0.1962\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.17342 to 0.19617, saving model to /content/drive/MyDrive/Transformers/voc25k/weights_rmsprop.ckpt\n",
            "Epoch 3/30\n",
            "164/164 [==============================] - 149s 906ms/step - loss: 0.7588 - accuracy: 0.2029 - val_loss: 0.7357 - val_accuracy: 0.2182\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.19617 to 0.21817, saving model to /content/drive/MyDrive/Transformers/voc25k/weights_rmsprop.ckpt\n",
            "Epoch 4/30\n",
            "164/164 [==============================] - 149s 909ms/step - loss: 0.7295 - accuracy: 0.2231 - val_loss: 0.7258 - val_accuracy: 0.2295\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.21817 to 0.22948, saving model to /content/drive/MyDrive/Transformers/voc25k/weights_rmsprop.ckpt\n",
            "Epoch 5/30\n",
            "164/164 [==============================] - 149s 910ms/step - loss: 0.7031 - accuracy: 0.2404 - val_loss: 0.7160 - val_accuracy: 0.2348\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.22948 to 0.23480, saving model to /content/drive/MyDrive/Transformers/voc25k/weights_rmsprop.ckpt\n",
            "Epoch 6/30\n",
            "164/164 [==============================] - 149s 909ms/step - loss: 0.6815 - accuracy: 0.2542 - val_loss: 0.7178 - val_accuracy: 0.2272\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.23480\n",
            "Epoch 7/30\n",
            "164/164 [==============================] - 149s 907ms/step - loss: 0.6624 - accuracy: 0.2668 - val_loss: 0.6999 - val_accuracy: 0.2446\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.23480 to 0.24463, saving model to /content/drive/MyDrive/Transformers/voc25k/weights_rmsprop.ckpt\n",
            "Epoch 8/30\n",
            "164/164 [==============================] - 149s 910ms/step - loss: 0.6455 - accuracy: 0.2788 - val_loss: 0.7139 - val_accuracy: 0.2491\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.24463 to 0.24911, saving model to /content/drive/MyDrive/Transformers/voc25k/weights_rmsprop.ckpt\n",
            "Epoch 9/30\n",
            "164/164 [==============================] - 149s 910ms/step - loss: 0.6274 - accuracy: 0.2909 - val_loss: 0.7030 - val_accuracy: 0.2530\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.24911 to 0.25300, saving model to /content/drive/MyDrive/Transformers/voc25k/weights_rmsprop.ckpt\n",
            "Epoch 10/30\n",
            "164/164 [==============================] - 149s 910ms/step - loss: 0.6119 - accuracy: 0.3042 - val_loss: 0.7072 - val_accuracy: 0.2440\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.25300\n",
            "Epoch 11/30\n",
            "164/164 [==============================] - 149s 910ms/step - loss: 0.5961 - accuracy: 0.3161 - val_loss: 0.7066 - val_accuracy: 0.2538\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.25300 to 0.25376, saving model to /content/drive/MyDrive/Transformers/voc25k/weights_rmsprop.ckpt\n",
            "Epoch 12/30\n",
            "164/164 [==============================] - 149s 909ms/step - loss: 0.5812 - accuracy: 0.3293 - val_loss: 0.7041 - val_accuracy: 0.2548\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.25376 to 0.25480, saving model to /content/drive/MyDrive/Transformers/voc25k/weights_rmsprop.ckpt\n",
            "Epoch 13/30\n",
            "164/164 [==============================] - 149s 910ms/step - loss: 0.5646 - accuracy: 0.3422 - val_loss: 0.7247 - val_accuracy: 0.2421\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.25480\n",
            "Epoch 14/30\n",
            "164/164 [==============================] - 149s 909ms/step - loss: 0.5498 - accuracy: 0.3557 - val_loss: 0.7266 - val_accuracy: 0.2551\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.25480 to 0.25514, saving model to /content/drive/MyDrive/Transformers/voc25k/weights_rmsprop.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x7f8ccd8c3a70>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 546, in __del__\n",
            "    handle=self._handle, deleter=self._deleter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1264, in delete_iterator\n",
            "    _ctx, \"DeleteIterator\", name, handle, deleter)\n",
            "KeyboardInterrupt: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/30\n",
            " 12/164 [=>............................] - ETA: 2:06 - loss: 0.5239 - accuracy: 0.3698"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-373dd4c09aa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Qvebl8FHsG",
        "outputId": "0049bdd3-8796-4d58-c8bc-6285a4f28b41"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(googledrive_path)\n",
        "transformer.load_weights(latest)"
      ],
      "id": "j5Qvebl8FHsG",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f88bc91b350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8447490b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f388201-838e-4ee8-9e0d-993bb0106500"
      },
      "source": [
        "ar_vocab = ar_vectorization.get_vocabulary()\n",
        "ar_index_lookup = dict(zip(range(len(ar_vocab)), ar_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = ar_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = ar_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in val_pairs]\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts[:30])\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(input_sentence, '\\n', translated)\n",
        "    print('*'*50)"
      ],
      "id": "8447490b",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tom drove the car. \n",
            " [start] توم [UNK] [end]\n",
            "**************************************************\n",
            "the june incident in in beijing after the crackdown hong kong people hold annual candlelight vigil demanding the vindication of june. \n",
            " [start] تم نشر هذا العام في مدينة مكسيكو متنوعة من قبل [UNK] في مدينة [UNK] في مدينة مكسيكو [end]\n",
            "**************************************************\n",
            "the june incident in in beijing after the crackdown hong kong people hold annual candlelight vigil demanding the vindication of june. \n",
            " [start] تم نشر هذا العام في مدينة مكسيكو متنوعة من قبل [UNK] في مدينة [UNK] في مدينة مكسيكو [end]\n",
            "**************************************************\n",
            "It is dangerous to drive so fast. \n",
            " [start] إنه [UNK] إلى [UNK] [end]\n",
            "**************************************************\n",
            "mr wu had this to say about the end of the games. \n",
            " [start] ما [UNK] [UNK] هذه التدوينة [end]\n",
            "**************************************************\n",
            "the june incident in in beijing after the crackdown hong kong people hold annual candlelight vigil demanding the vindication of june. \n",
            " [start] تم نشر هذا العام في مدينة مكسيكو متنوعة من قبل [UNK] في مدينة [UNK] في مدينة مكسيكو [end]\n",
            "**************************************************\n",
            "egyptian blogger arrested and prevented from covering a taxi drivers strike global voices. \n",
            " [start] المدون المصري المصري [UNK] [UNK] من الى المدون المغربي الاصوات العالمية [end]\n",
            "**************************************************\n",
            "recently a new book documenting the ancient art of henna was released the book entitled moor a henna atlas of morocco contains illustrations and photographs of the beautiful moroccan version of the art form a sneak peek. \n",
            " [start] نشرت منظمة [UNK] منظمة تبادل الاعلام الاجتماعي في مدونة [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "**************************************************\n",
            "sovereigns of cyberspace. \n",
            " [start] [UNK] [UNK] [end]\n",
            "**************************************************\n",
            "It is dangerous to drive so fast. \n",
            " [start] إنه [UNK] إلى [UNK] [end]\n",
            "**************************************************\n",
            "He likes watching TV. \n",
            " [start] يحب يحب مشاهدة التلفاز [end]\n",
            "**************************************************\n",
            "You have to learn to put up with this weather. \n",
            " [start] عليك أن تذهب إلى [UNK] [UNK] [UNK] [end]\n",
            "**************************************************\n",
            "The Internet is very useful for knowing the circumstances of each part of the world. \n",
            " [start] العالم العربي من اجل [UNK] كل شيء اخر [UNK] [end]\n",
            "**************************************************\n",
            "egyptian blogger arrested and prevented from covering a taxi drivers strike global voices. \n",
            " [start] المدون المصري المصري [UNK] [UNK] من الى المدون المغربي الاصوات العالمية [end]\n",
            "**************************************************\n",
            "mughniyeh was featured on president bush s top most wanted terrorists list of october and he was on the fbi s most wanted list he was alleged to be behind the us marines barracks bombing in beirut which claimed the lives of marines. \n",
            " [start] مدونة تكتب عن موضوع الاعلام [UNK] عن [UNK] في العالم العربي [UNK] في مدينة [UNK] في نوفمبر تشرين الثاني ان\n",
            "**************************************************\n",
            "bellavista santiago chile photo by patricia vargas used with permission. \n",
            " [start] شيلي تصوير عقيب خان [end]\n",
            "**************************************************\n",
            "educacion viva live education has released the first of their videos challenging traditional education systems titled i don t believe in schools but i do believe in education in the subtitled video more than men and women read aloud a poem on the educational system and how it is different from what they believe education is. \n",
            " [start] تعتبر [UNK] هي واحدة [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] في [UNK] [UNK] في\n",
            "**************************************************\n",
            "the june incident in in beijing after the crackdown hong kong people hold annual candlelight vigil demanding the vindication of june. \n",
            " [start] تم نشر هذا العام في مدينة مكسيكو متنوعة من قبل [UNK] في مدينة [UNK] في مدينة مكسيكو [end]\n",
            "**************************************************\n",
            "It is dangerous to drive so fast. \n",
            " [start] إنه [UNK] إلى [UNK] [end]\n",
            "**************************************************\n",
            "You have to learn to put up with this weather. \n",
            " [start] عليك أن تذهب إلى [UNK] [UNK] [UNK] [end]\n",
            "**************************************************\n",
            "with that in mind eff together with global voices advocacy have created a set of questions to consider this list is by no means exhaustive but should offer a starting point from which bloggers can develop their own contingency plans. \n",
            " [start] مع ذلك فان في هذا المقال [UNK] [UNK] [UNK] من قبل وسايل الاعلام الاجتماعي الذي [UNK] [UNK] [UNK] [UNK] [UNK]\n",
            "**************************************************\n",
            "The rumor isn't true. \n",
            " [start] إنه [UNK] ليس ذلك [end]\n",
            "**************************************************\n",
            "Tom drove the car. \n",
            " [start] توم [UNK] [end]\n",
            "**************************************************\n",
            "suara blogger indonesia explains how the indonesian government blocks internet content in the country through the help of local internet service providers indonesia has one of the most active social media communities in the world. \n",
            " [start] نشرت المدونة المصرية زينوبيا عن حقوق الانسان في مجال الانترنت في مجال حقوق الانسان في العالم العربي [UNK] [UNK] [UNK]\n",
            "**************************************************\n",
            "My grandfather comes from Osaka. \n",
            " [start] [UNK] [UNK] [UNK] من فضلك [end]\n",
            "**************************************************\n",
            "educacion viva live education has released the first of their videos challenging traditional education systems titled i don t believe in schools but i do believe in education in the subtitled video more than men and women read aloud a poem on the educational system and how it is different from what they believe education is. \n",
            " [start] تعتبر [UNK] هي واحدة [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] في [UNK] [UNK] في\n",
            "**************************************************\n",
            "They are very big. \n",
            " [start] الجميع جداً [end]\n",
            "**************************************************\n",
            "What is going on here? \n",
            " [start] ما الذي حدث هنا [end]\n",
            "**************************************************\n",
            "Do you want a drink? \n",
            " [start] هل تريد أن [UNK] [end]\n",
            "**************************************************\n",
            "egyptian blogger arrested and prevented from covering a taxi drivers strike global voices. \n",
            " [start] المدون المصري المصري [UNK] [UNK] من الى المدون المغربي الاصوات العالمية [end]\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iD1guTcL5zs",
        "outputId": "eea77450-8c90-423c-df09-59aa3b56cf9a"
      },
      "source": [
        "input_sentence = 'cold war'\n",
        "translated = decode_sequence(input_sentence)\n",
        "print(input_sentence, '\\n', translated)\n",
        "print('*'*50)"
      ],
      "id": "2iD1guTcL5zs",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cold war \n",
            " [start] الحرب الحرب [end]\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}