{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyarabic\n!git clone https://github.com/moaaztaha/Arabic-English-Translation-Transformers","metadata":{"id":"0R53kjrYGpSc","outputId":"25e29470-6a5b-4cb8-8fba-6943fd0ca93c","execution":{"iopub.status.busy":"2021-06-08T01:34:16.627960Z","iopub.execute_input":"2021-06-08T01:34:16.628366Z","iopub.status.idle":"2021-06-08T01:34:26.014739Z","shell.execute_reply.started":"2021-06-08T01:34:16.628281Z","shell.execute_reply":"2021-06-08T01:34:26.013775Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyarabic in /opt/conda/lib/python3.7/site-packages (0.6.10)\nCloning into 'Arabic-English-Translation-Transformers'...\nremote: Enumerating objects: 39, done.\u001b[K\nremote: Counting objects: 100% (39/39), done.\u001b[K\nremote: Compressing objects: 100% (29/29), done.\u001b[K\nremote: Total 39 (delta 13), reused 34 (delta 8), pack-reused 0\u001b[K\nUnpacking objects: 100% (39/39), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"# modules\nimport random\nimport string\nimport re\nfrom pathlib import Path\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n\nimport pandas as pd\nfrom tqdm import tqdm\n\n\nimport pyarabic.araby as araby\nfrom pyarabic.araby import strip_tashkeel, strip_tatweel","metadata":{"id":"e9e97fa1","execution":{"iopub.status.busy":"2021-06-08T02:16:47.414915Z","iopub.execute_input":"2021-06-08T02:16:47.415253Z","iopub.status.idle":"2021-06-08T02:16:47.421088Z","shell.execute_reply.started":"2021-06-08T02:16:47.415225Z","shell.execute_reply":"2021-06-08T02:16:47.419702Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"### Data Preprocessing ","metadata":{"id":"1710411f"}},{"cell_type":"code","source":"ar = pd.read_table('../input/ar-en-translation-small/ArabicNewData.txt', delimiter='\\\\n', names=['ar'])\nen = pd.read_table('../input/ar-en-translation-small/EnglishNewData.txt', delimiter='\\\\n', names=['en'])\n\nen['ar'] = ar['ar']\ndf = en.copy()\ndf = df.iloc[:35118]","metadata":{"id":"1RNDMX9cizGW","outputId":"e7f0bb9a-8761-44a8-c1cc-3f0331ca3fe3","execution":{"iopub.status.busy":"2021-06-08T02:16:47.955355Z","iopub.execute_input":"2021-06-08T02:16:47.955686Z","iopub.status.idle":"2021-06-08T02:16:48.136995Z","shell.execute_reply.started":"2021-06-08T02:16:47.955644Z","shell.execute_reply":"2021-06-08T02:16:48.136060Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py:767: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n  return read_csv(**locals())\n","output_type":"stream"}]},{"cell_type":"code","source":"morphs = [strip_tashkeel, strip_tatweel]\n\ndef fix_ar(sent):\n  sent = split_al_sent(sent)\n  tokens = araby.tokenize(sent, morphs=morphs)\n  sent = araby.normalize_hamza(' '.join(tokens), method='tasheel')\n  return sent","metadata":{"id":"T2YTqqOTGl5c","execution":{"iopub.status.busy":"2021-06-08T02:16:48.455116Z","iopub.execute_input":"2021-06-08T02:16:48.455428Z","iopub.status.idle":"2021-06-08T02:16:48.461638Z","shell.execute_reply.started":"2021-06-08T02:16:48.455402Z","shell.execute_reply":"2021-06-08T02:16:48.460738Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def split_al(word):\n    if word.startswith('ال'):\n        return word[:2], word[2:]\n    else: \n        return word\n\ndef split_al_sent(sent):\n    ww = []\n    for word in sent.split():\n        out = split_al(word)\n        if type(out) is tuple:\n            for w in out:\n                ww.append(w)\n        else:\n            ww.append(word)\n    return ' '.join(w for w in ww)","metadata":{"id":"7WhmXTv1KRkd","execution":{"iopub.status.busy":"2021-06-08T02:16:48.992161Z","iopub.execute_input":"2021-06-08T02:16:48.992476Z","iopub.status.idle":"2021-06-08T02:16:48.998243Z","shell.execute_reply.started":"2021-06-08T02:16:48.992448Z","shell.execute_reply":"2021-06-08T02:16:48.997288Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"df['ar'] = df.apply(lambda row: fix_ar(row.ar), axis=1)","metadata":{"id":"QGuKlu3mFIZc","execution":{"iopub.status.busy":"2021-06-08T02:16:50.345045Z","iopub.execute_input":"2021-06-08T02:16:50.345366Z","iopub.status.idle":"2021-06-08T02:16:51.796892Z","shell.execute_reply.started":"2021-06-08T02:16:50.345330Z","shell.execute_reply":"2021-06-08T02:16:51.795902Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"text_pairs = []\nfor idx, row in df.iterrows():\n  en, ar = row['en'], row['ar']\n  ar = \"[start] \" + ar + \" [end]\"\n  text_pairs.append((en, ar))","metadata":{"id":"be905b2c","execution":{"iopub.status.busy":"2021-06-08T02:16:51.799257Z","iopub.execute_input":"2021-06-08T02:16:51.799840Z","iopub.status.idle":"2021-06-08T02:16:54.618551Z","shell.execute_reply.started":"2021-06-08T02:16:51.799800Z","shell.execute_reply":"2021-06-08T02:16:54.617702Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"for idx, row in df.iterrows():\n  if len(row.ar.split()) < 1:\n    print(row.ar, '\\n*')\n    print(row.en)","metadata":{"id":"fAxNAdK2H0eB","execution":{"iopub.status.busy":"2021-06-08T02:16:58.012634Z","iopub.execute_input":"2021-06-08T02:16:58.013120Z","iopub.status.idle":"2021-06-08T02:17:00.598315Z","shell.execute_reply.started":"2021-06-08T02:16:58.013084Z","shell.execute_reply":"2021-06-08T02:17:00.597570Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"for _ in range(2):\n    print(random.choice(text_pairs))","metadata":{"id":"296e4594","outputId":"cf5ca9a6-e5ae-45ff-9b35-1dac88910f32","execution":{"iopub.status.busy":"2021-06-08T02:17:00.600320Z","iopub.execute_input":"2021-06-08T02:17:00.600692Z","iopub.status.idle":"2021-06-08T02:17:00.605892Z","shell.execute_reply.started":"2021-06-08T02:17:00.600644Z","shell.execute_reply":"2021-06-08T02:17:00.605074Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"(\"Darling, we're going to forget all about these dreams and think about something cheerful, aren't we?\", '[start] عزيزتي , سننسى كل هذه ال احلام و نفكر في شىء مرح , اليس كذلك ؟ [end]')\n(\"But you can't murder me just like that!\", '[start] لكن لو تقتلني ! فستكون تلك جريمة قتل [end]')\n","output_type":"stream"}]},{"cell_type":"code","source":"len(text_pairs)","metadata":{"id":"o6kRoro9iBOe","outputId":"1ec02783-32ee-45c0-bef7-e64dfb28b8c2","execution":{"iopub.status.busy":"2021-06-08T02:17:00.607746Z","iopub.execute_input":"2021-06-08T02:17:00.608167Z","iopub.status.idle":"2021-06-08T02:17:00.620306Z","shell.execute_reply.started":"2021-06-08T02:17:00.608132Z","shell.execute_reply":"2021-06-08T02:17:00.619437Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"35118"},"metadata":{}}]},{"cell_type":"code","source":"random.shuffle(text_pairs)\nnum_val_samples = int(0.15 * len(text_pairs))\nnum_train_samples = len(text_pairs) -  num_val_samples\ntrain_pairs = text_pairs[: num_train_samples]\nval_pairs = text_pairs[num_train_samples: num_train_samples + num_val_samples]","metadata":{"id":"c1283f6f","execution":{"iopub.status.busy":"2021-06-08T02:17:01.800249Z","iopub.execute_input":"2021-06-08T02:17:01.800560Z","iopub.status.idle":"2021-06-08T02:17:01.847161Z","shell.execute_reply.started":"2021-06-08T02:17:01.800532Z","shell.execute_reply":"2021-06-08T02:17:01.846417Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"print(f\"{len(text_pairs)} total pairs\")\nprint(f\"{len(train_pairs)} training pairs\")\nprint(f\"{len(val_pairs)} validation pairs\")","metadata":{"id":"a7a1f8cd","outputId":"2ff87303-7ba6-43a8-f9f1-fdc7db9a7f56","execution":{"iopub.status.busy":"2021-06-08T02:17:02.645892Z","iopub.execute_input":"2021-06-08T02:17:02.646210Z","iopub.status.idle":"2021-06-08T02:17:02.654338Z","shell.execute_reply.started":"2021-06-08T02:17:02.646181Z","shell.execute_reply":"2021-06-08T02:17:02.653626Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"35118 total pairs\n29851 training pairs\n5267 validation pairs\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Vectorizing the text data ","metadata":{"id":"d5f6d84e"}},{"cell_type":"code","source":"strip_chars = string.punctuation\nstrip_chars = strip_chars.replace(\"[\", \"\")\nstrip_chars = strip_chars.replace(\"]\", \"\")\n\n\nvocab_size = 20000\nsequence_length = 50\nbatch_size = 265\n\ndef custom_standardization(input_string):\n    return tf.strings.regex_replace(input_string, \"[%s]\" % re.escape(strip_chars), \"\")\n\neng_vectorization = TextVectorization(\n            # max_tokens=vocab_size, \n            output_mode='int', \n            output_sequence_length=sequence_length)\n\nar_vectorization = TextVectorization(\n    # max_tokens=vocab_size,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length + 1,\n    standardize=custom_standardization,\n    max_tokens=vocab_size)\n\neng_texts = [pair[0] for pair in text_pairs]\nar_texts = [pair[1] for pair in text_pairs]\neng_vectorization.adapt(eng_texts)\nar_vectorization.adapt(ar_texts)","metadata":{"id":"487ed66f","execution":{"iopub.status.busy":"2021-06-08T02:17:03.954239Z","iopub.execute_input":"2021-06-08T02:17:03.954544Z","iopub.status.idle":"2021-06-08T02:17:04.856227Z","shell.execute_reply.started":"2021-06-08T02:17:03.954516Z","shell.execute_reply":"2021-06-08T02:17:04.854499Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"len(ar_vectorization.get_vocabulary()), len(eng_vectorization.get_vocabulary())","metadata":{"id":"ubW5QOJtLzMI","outputId":"255cd7fe-f248-4210-8572-21cafce65778","execution":{"iopub.status.busy":"2021-06-08T02:17:04.859040Z","iopub.execute_input":"2021-06-08T02:17:04.859565Z","iopub.status.idle":"2021-06-08T02:17:04.938344Z","shell.execute_reply.started":"2021-06-08T02:17:04.859525Z","shell.execute_reply":"2021-06-08T02:17:04.937688Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"(20000, 13164)"},"metadata":{}}]},{"cell_type":"code","source":"len(ar_vectorization.get_vocabulary()), len(eng_vectorization.get_vocabulary())","metadata":{"id":"wep-jkjyLWz6","outputId":"fa3d480c-3075-4d24-84c8-25324524b0fc","execution":{"iopub.status.busy":"2021-06-08T02:17:04.939783Z","iopub.execute_input":"2021-06-08T02:17:04.940155Z","iopub.status.idle":"2021-06-08T02:17:05.011110Z","shell.execute_reply.started":"2021-06-08T02:17:04.940116Z","shell.execute_reply":"2021-06-08T02:17:05.010101Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"(20000, 13164)"},"metadata":{}}]},{"cell_type":"code","source":"def format_dataset(eng, ar):\n    eng = eng_vectorization(eng)\n    ar = ar_vectorization(ar)\n    return ({\"encoder_inputs\": eng, \"decoder_inputs\": ar[:, :-1],}, ar[:, 1:])\n\n\ndef make_dataset(pairs):\n    eng_texts, ar_texts = zip(*pairs)\n    eng_texts = list(eng_texts)\n    ar_texts = list(ar_texts)\n    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ar_texts))\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.map(format_dataset)\n    return dataset.shuffle(2048).prefetch(16).cache()","metadata":{"id":"V5qiqjOWdVz1","execution":{"iopub.status.busy":"2021-06-08T02:17:05.013252Z","iopub.execute_input":"2021-06-08T02:17:05.013639Z","iopub.status.idle":"2021-06-08T02:17:05.021566Z","shell.execute_reply.started":"2021-06-08T02:17:05.013599Z","shell.execute_reply":"2021-06-08T02:17:05.020566Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"train_ds = make_dataset(train_pairs)\nval_ds = make_dataset(val_pairs)","metadata":{"id":"7a3ed140","execution":{"iopub.status.busy":"2021-06-08T02:17:05.596886Z","iopub.execute_input":"2021-06-08T02:17:05.597209Z","iopub.status.idle":"2021-06-08T02:17:06.245999Z","shell.execute_reply.started":"2021-06-08T02:17:05.597181Z","shell.execute_reply":"2021-06-08T02:17:06.245218Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"for inputs, targets in train_ds.take(1):\n    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n    print(f\"targets.shape: {targets.shape}\")","metadata":{"id":"3902789f","outputId":"b85367db-eb0f-4bb3-9cf7-f2cf54ee12e5","execution":{"iopub.status.busy":"2021-06-08T02:17:06.247956Z","iopub.execute_input":"2021-06-08T02:17:06.248284Z","iopub.status.idle":"2021-06-08T02:17:06.519611Z","shell.execute_reply.started":"2021-06-08T02:17:06.248250Z","shell.execute_reply":"2021-06-08T02:17:06.518592Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"inputs[\"encoder_inputs\"].shape: (265, 50)\ninputs[\"decoder_inputs\"].shape: (265, 50)\ntargets.shape: (265, 50)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Building the Model ","metadata":{"id":"4fa0936c"}},{"cell_type":"code","source":"class TransformerEncoder(layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super(TransformerEncoder, self).__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.attention = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.dense_proj = keras.Sequential(\n            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.supports_masking = True\n\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n        attention_output = self.attention(\n            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n        )\n        proj_input = self.layernorm_1(inputs + attention_output)\n        proj_output = self.dense_proj(proj_input)\n        return self.layernorm_2(proj_input + proj_output)\n\n    def get_config(self):\n\n      config = super().get_config().copy()\n      config.update({\n          'embed_dim': self.embed_dim,\n          'dense_dim': self.dense_dim,\n          'num_heads': self.num_heads,\n      })\n      return config\n\nclass PositionalEmbedding(layers.Layer):\n    def __init__(self, sequence_length, vocab_size, embed_dim, pretrained=False, weights=False, **kwargs):\n        super(PositionalEmbedding, self).__init__(**kwargs)\n        if not pretrained:\n          self.token_embeddings = layers.Embedding(\n              input_dim=vocab_size, output_dim=embed_dim\n          )\n        else:\n          # pre-trained\n          self.token_embeddings = layers.Embedding(\n              input_dim=vocab_size, output_dim=embed_dim, weights=[weights]\n          ) \n\n        self.position_embeddings = layers.Embedding(\n            input_dim=sequence_length, output_dim=embed_dim\n        )\n        self.sequence_length = sequence_length\n        self.vocab_size = vocab_size\n        self.embed_dim = embed_dim\n      \n    def get_config(self):\n\n      config = super().get_config().copy()\n      config.update({\n      'sequence_length': self.sequence_length,\n      'vocab_size': self.vocab_size,\n      'embed_dim': self.embed_dim,\n      })\n      return config\n\n    def call(self, inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start=0, limit=length, delta=1)\n        embedded_tokens = self.token_embeddings(inputs)\n        embedded_positions = self.position_embeddings(positions)\n        return embedded_tokens + embedded_positions\n\n    def compute_mask(self, inputs, mask=None):\n        return tf.math.not_equal(inputs, 0)\n\n\nclass TransformerDecoder(layers.Layer):\n    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n        super(TransformerDecoder, self).__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.latent_dim = latent_dim\n        self.num_heads = num_heads\n        self.attention_1 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.attention_2 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.dense_proj = keras.Sequential(\n            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.layernorm_3 = layers.LayerNormalization()\n        self.supports_masking = True\n\n\n    def get_config(self):\n\n      config = super().get_config().copy()\n      config.update({\n      'embed_dim': self.embed_dim,\n      'latent_dim': self.latent_dim,\n      'num_heads': self.num_heads,\n      })\n      return config\n\n    def call(self, inputs, encoder_outputs, mask=None):\n        causal_mask = self.get_causal_attention_mask(inputs)\n        if mask is not None:\n            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n            padding_mask = tf.minimum(padding_mask, causal_mask)\n\n        attention_output_1 = self.attention_1(\n            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n        )\n        out_1 = self.layernorm_1(inputs + attention_output_1)\n\n        attention_output_2 = self.attention_2(\n            query=out_1,\n            value=encoder_outputs,\n            key=encoder_outputs,\n            attention_mask=padding_mask,\n        )\n        out_2 = self.layernorm_2(out_1 + attention_output_2)\n\n        proj_output = self.dense_proj(out_2)\n        return self.layernorm_3(out_2 + proj_output)\n\n    def get_causal_attention_mask(self, inputs):\n        input_shape = tf.shape(inputs)\n        batch_size, sequence_length = input_shape[0], input_shape[1]\n        i = tf.range(sequence_length)[:, tf.newaxis]\n        j = tf.range(sequence_length)\n        mask = tf.cast(i >= j, dtype=\"int32\")\n        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n        mult = tf.concat(\n            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n            axis=0,\n        )\n        return tf.tile(mask, mult)","metadata":{"id":"b3baf452","execution":{"iopub.status.busy":"2021-06-08T02:17:07.222610Z","iopub.execute_input":"2021-06-08T02:17:07.222939Z","iopub.status.idle":"2021-06-08T02:17:07.247405Z","shell.execute_reply.started":"2021-06-08T02:17:07.222907Z","shell.execute_reply":"2021-06-08T02:17:07.246264Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"!wget http://nlp.stanford.edu/data/glove.6B.zip\n!unzip -q glove.6B.zip","metadata":{"id":"fpXVu3eA_b9P","execution":{"iopub.status.busy":"2021-06-08T02:17:20.072791Z","iopub.execute_input":"2021-06-08T02:17:20.073181Z","iopub.status.idle":"2021-06-08T02:20:23.160034Z","shell.execute_reply.started":"2021-06-08T02:17:20.073151Z","shell.execute_reply":"2021-06-08T02:20:23.158925Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"--2021-06-08 02:17:20--  http://nlp.stanford.edu/data/glove.6B.zip\nResolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\nConnecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://nlp.stanford.edu/data/glove.6B.zip [following]\n--2021-06-08 02:17:20--  https://nlp.stanford.edu/data/glove.6B.zip\nConnecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n--2021-06-08 02:17:21--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\nResolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\nConnecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 862182613 (822M) [application/zip]\nSaving to: ‘glove.6B.zip’\n\nglove.6B.zip        100%[===================>] 822.24M  5.26MB/s    in 2m 40s  \n\n2021-06-08 02:20:01 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\npath_to_glove_file = os.path.join(\n    os.path.expanduser(\"~\"), f\"{os.getcwd()}/glove.6B.300d.txt\"\n)\n\nembeddings_index = {}\nwith open(path_to_glove_file) as f:\n    for line in f:\n        word, coefs = line.split(maxsplit=1)\n        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n        embeddings_index[word] = coefs\n\nprint(\"Found %s word vectors.\" % len(embeddings_index))","metadata":{"id":"afjYy3g6BM2K","outputId":"e32988e0-c411-403e-c96b-f847eb6a7677","execution":{"iopub.status.busy":"2021-06-08T02:21:45.994677Z","iopub.execute_input":"2021-06-08T02:21:45.995027Z","iopub.status.idle":"2021-06-08T02:22:15.646535Z","shell.execute_reply.started":"2021-06-08T02:21:45.994991Z","shell.execute_reply":"2021-06-08T02:22:15.644971Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Found 400000 word vectors.\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab = eng_vectorization.get_vocabulary()\nword_index = dict(zip(vocab, range(len(vocab))))","metadata":{"id":"XRNRUzOCtccc","execution":{"iopub.status.busy":"2021-06-08T02:22:19.678371Z","iopub.execute_input":"2021-06-08T02:22:19.678697Z","iopub.status.idle":"2021-06-08T02:22:19.715575Z","shell.execute_reply.started":"2021-06-08T02:22:19.678659Z","shell.execute_reply":"2021-06-08T02:22:19.714615Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"import gensim\nimport re\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:15:46.077526Z","iopub.execute_input":"2021-06-08T03:15:46.077892Z","iopub.status.idle":"2021-06-08T03:15:46.207948Z","shell.execute_reply.started":"2021-06-08T03:15:46.077854Z","shell.execute_reply":"2021-06-08T03:15:46.207172Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"def get_weights(vectorizer, embeddings_path, is_gensim=False):\n    path_to_glove_file = embeddings_path\n    \n    if is_gensim:\n        embeddings_index = gensim.models.Word2Vec.load(embeddings_path)\n        \n    else:\n        embeddings_index = {}\n        with open(path_to_glove_file) as f:\n            for line in f:\n                word, coefs = line.split(maxsplit=1)\n                coefs = np.fromstring(coefs, \"f\", sep=\" \")\n                embeddings_index[word] = coefs\n    \n    if not is_gensim:\n        print(\"Found %s word vectors.\" % len(dict(embeddings_index)))\n    else:\n        print(\"Found %s word vectors.\" % (embeddings_index.wv.vectors.shape[0]))\n\n    \n    \n    vocab = vectorizer.get_vocabulary()\n    word_index = dict(zip(vocab, range(len(vocab))))\n    num_tokens = len(vocab)\n    embedding_dim = 300\n    hits = 0\n    misses = 0\n\n    # Prepare embedding matrix\n    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n    for word, i in word_index.items():\n        if not is_gensim:\n            embedding_vector = embeddings_index.get(word)\n        else:\n            if word in embeddings_index.wv:\n                embedding_vector = embeddings_index.wv[word]\n            else:\n                embedding_vector = None\n        if embedding_vector is not None:\n            # Words not found in embedding index will be all-zeros.\n            # This includes the representation for \"padding\" and \"OOV\"\n            embedding_matrix[i] = embedding_vector\n            hits += 1\n        else:\n            embedding_matrix[i] = np.random.uniform(-.1, .1, size=(embedding_dim))\n            misses += 1\n    print(\"Converted %d words (%d misses)\" % (hits, misses))\n    return embedding_matrix","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:46:29.636942Z","iopub.execute_input":"2021-06-08T03:46:29.637271Z","iopub.status.idle":"2021-06-08T03:46:29.674663Z","shell.execute_reply.started":"2021-06-08T03:46:29.637241Z","shell.execute_reply":"2021-06-08T03:46:29.673702Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"english_embeddings = get_weights(eng_vectorization, './glove.6B.300d.txt')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:47:05.607322Z","iopub.execute_input":"2021-06-08T03:47:05.607709Z","iopub.status.idle":"2021-06-08T03:47:35.559143Z","shell.execute_reply.started":"2021-06-08T03:47:05.607653Z","shell.execute_reply":"2021-06-08T03:47:35.557315Z"},"trusted":true},"execution_count":197,"outputs":[{"name":"stdout","text":"Found 400000 word vectors.\nConverted 11896 words (1268 misses)\n","output_type":"stream"}]},{"cell_type":"code","source":"# ! wget https://bakrianoo.ewr1.vultrobjects.com/aravec/full_grams_cbow_300_wiki.zip\n# ! unzip -q full_grams_cbow_300_wiki.zip","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:46:30.659781Z","iopub.execute_input":"2021-06-08T03:46:30.660121Z","iopub.status.idle":"2021-06-08T03:46:30.663804Z","shell.execute_reply.started":"2021-06-08T03:46:30.660094Z","shell.execute_reply":"2021-06-08T03:46:30.662582Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"arabic_embeddings = get_weights(ar_vectorization, './full_grams_cbow_300_wiki.mdl', is_gensim=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:46:30.842479Z","iopub.execute_input":"2021-06-08T03:46:30.842754Z","iopub.status.idle":"2021-06-08T03:46:53.711963Z","shell.execute_reply.started":"2021-06-08T03:46:30.842728Z","shell.execute_reply":"2021-06-08T03:46:53.710792Z"},"trusted":true},"execution_count":196,"outputs":[{"name":"stdout","text":"Found 662109 word vectors.\nConverted 12646 words (7354 misses)\n","output_type":"stream"}]},{"cell_type":"code","source":"ar_vocab_size = len(ar_vectorization.get_vocabulary())\nen_vocab_size = len(eng_vectorization.get_vocabulary())\nen_vocab_size, ar_vocab_size","metadata":{"id":"U0rA0C4s1OVW","outputId":"1d2f5bc1-65d4-4e4e-cd22-8fad12f6cc0e","execution":{"iopub.status.busy":"2021-06-08T03:47:59.830643Z","iopub.execute_input":"2021-06-08T03:47:59.830984Z","iopub.status.idle":"2021-06-08T03:47:59.906741Z","shell.execute_reply.started":"2021-06-08T03:47:59.830952Z","shell.execute_reply":"2021-06-08T03:47:59.905831Z"},"trusted":true},"execution_count":199,"outputs":[{"execution_count":199,"output_type":"execute_result","data":{"text/plain":"(13164, 20000)"},"metadata":{}}]},{"cell_type":"code","source":"embed_dim = 300\nlatent_dim = 2048\nnum_heads = 8\n\nencoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\nx = PositionalEmbedding(sequence_length, en_vocab_size, embed_dim, pretrained=True, weights=english_embeddings)(encoder_inputs)\n# x = PositionalEmbedding(sequence_length, num_tokens, embed_dim)(encoder_inputs)\nencoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\nencoder = keras.Model(encoder_inputs, encoder_outputs)\n\ndecoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\nencoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\nx = PositionalEmbedding(sequence_length, ar_vocab_size, embed_dim, pretrained=True, weights=arabic_embeddings)(decoder_inputs)\n# x = PositionalEmbedding(sequence_length, ar_vocab_size, embed_dim)(decoder_inputs)\nx = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\nx = layers.Dropout(0.5)(x)\ndecoder_outputs = layers.Dense(ar_vocab_size, activation=\"softmax\")(x)\ndecoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n\ndecoder_outputs = decoder([decoder_inputs, encoder_outputs])\ntransformer = keras.Model(\n    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n)","metadata":{"id":"04c57e1e","execution":{"iopub.status.busy":"2021-06-08T03:49:47.423352Z","iopub.execute_input":"2021-06-08T03:49:47.423713Z","iopub.status.idle":"2021-06-08T03:49:48.045217Z","shell.execute_reply.started":"2021-06-08T03:49:47.423679Z","shell.execute_reply":"2021-06-08T03:49:48.044246Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"googledrive_path = './pretrained_both'","metadata":{"id":"vt9sp6Yrb4pE","execution":{"iopub.status.busy":"2021-06-08T03:49:49.471793Z","iopub.execute_input":"2021-06-08T03:49:49.472124Z","iopub.status.idle":"2021-06-08T03:49:49.477189Z","shell.execute_reply.started":"2021-06-08T03:49:49.472094Z","shell.execute_reply":"2021-06-08T03:49:49.476150Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"from keras import callbacks\nearly_stopping_cb = callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=True)\ncheckpoint_cb = callbacks.ModelCheckpoint(googledrive_path+'/weights_adam.ckpt', monitor='val_accuracy', save_weights_only=True,verbose=True, save_best_only=True)\ntensorboard_callback = callbacks.TensorBoard(log_dir=googledrive_path+\"/logs\")\nlr_schr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=True, factor=0.3, min_lr=0.0001)\ncbs = [early_stopping_cb, checkpoint_cb, tensorboard_callback, lr_schr]","metadata":{"id":"wqmaEQ94kyB9","execution":{"iopub.status.busy":"2021-06-08T03:49:54.155540Z","iopub.execute_input":"2021-06-08T03:49:54.155939Z","iopub.status.idle":"2021-06-08T03:49:54.164631Z","shell.execute_reply.started":"2021-06-08T03:49:54.155904Z","shell.execute_reply":"2021-06-08T03:49:54.163841Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"epochs = 100  # This should be at least 30 for convergence\n\ntransformer.summary()\ntransformer.compile(\n    \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n)\ntransformer.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=cbs)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:50:03.472687Z","iopub.execute_input":"2021-06-08T03:50:03.473046Z","iopub.status.idle":"2021-06-08T04:02:41.112268Z","shell.execute_reply.started":"2021-06-08T03:50:03.473016Z","shell.execute_reply":"2021-06-08T04:02:41.111344Z"},"trusted":true},"execution_count":204,"outputs":[{"name":"stdout","text":"Model: \"transformer\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_inputs (InputLayer)     [(None, None)]       0                                            \n__________________________________________________________________________________________________\npositional_embedding_8 (Positio (None, None, 300)    3964200     encoder_inputs[0][0]             \n__________________________________________________________________________________________________\ndecoder_inputs (InputLayer)     [(None, None)]       0                                            \n__________________________________________________________________________________________________\ntransformer_encoder_4 (Transfor (None, None, 300)    4119848     positional_embedding_8[0][0]     \n__________________________________________________________________________________________________\nmodel_9 (Functional)            (None, None, 20000)  19042948    decoder_inputs[0][0]             \n                                                                 transformer_encoder_4[0][0]      \n==================================================================================================\nTotal params: 27,126,996\nTrainable params: 27,126,996\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/100\n113/113 [==============================] - 57s 483ms/step - loss: 1.0848 - accuracy: 0.2297 - val_loss: 0.8051 - val_accuracy: 0.3303\n\nEpoch 00001: val_accuracy improved from -inf to 0.33027, saving model to ./pretrained_both/weights_adam.ckpt\nEpoch 2/100\n113/113 [==============================] - 54s 474ms/step - loss: 0.7797 - accuracy: 0.3474 - val_loss: 0.7445 - val_accuracy: 0.3720\n\nEpoch 00002: val_accuracy improved from 0.33027 to 0.37196, saving model to ./pretrained_both/weights_adam.ckpt\nEpoch 3/100\n113/113 [==============================] - 54s 476ms/step - loss: 0.7033 - accuracy: 0.3805 - val_loss: 0.7138 - val_accuracy: 0.3864\n\nEpoch 00003: val_accuracy improved from 0.37196 to 0.38642, saving model to ./pretrained_both/weights_adam.ckpt\nEpoch 4/100\n113/113 [==============================] - 54s 476ms/step - loss: 0.6402 - accuracy: 0.4048 - val_loss: 0.6999 - val_accuracy: 0.3941\n\nEpoch 00004: val_accuracy improved from 0.38642 to 0.39413, saving model to ./pretrained_both/weights_adam.ckpt\nEpoch 5/100\n113/113 [==============================] - 53s 473ms/step - loss: 0.5850 - accuracy: 0.4269 - val_loss: 0.6870 - val_accuracy: 0.4045\n\nEpoch 00005: val_accuracy improved from 0.39413 to 0.40451, saving model to ./pretrained_both/weights_adam.ckpt\nEpoch 6/100\n113/113 [==============================] - 53s 473ms/step - loss: 0.5348 - accuracy: 0.4466 - val_loss: 0.6839 - val_accuracy: 0.4059\n\nEpoch 00006: val_accuracy improved from 0.40451 to 0.40587, saving model to ./pretrained_both/weights_adam.ckpt\nEpoch 7/100\n113/113 [==============================] - 53s 472ms/step - loss: 0.4889 - accuracy: 0.4683 - val_loss: 0.6898 - val_accuracy: 0.4023\n\nEpoch 00007: val_accuracy did not improve from 0.40587\nEpoch 8/100\n113/113 [==============================] - 53s 473ms/step - loss: 0.4481 - accuracy: 0.4914 - val_loss: 0.7031 - val_accuracy: 0.4022\n\nEpoch 00008: val_accuracy did not improve from 0.40587\n\nEpoch 00008: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\nEpoch 9/100\n113/113 [==============================] - 54s 474ms/step - loss: 0.3952 - accuracy: 0.5317 - val_loss: 0.6861 - val_accuracy: 0.4190\n\nEpoch 00009: val_accuracy improved from 0.40587 to 0.41904, saving model to ./pretrained_both/weights_adam.ckpt\nEpoch 10/100\n113/113 [==============================] - 53s 471ms/step - loss: 0.3452 - accuracy: 0.5789 - val_loss: 0.6964 - val_accuracy: 0.4181\n\nEpoch 00010: val_accuracy did not improve from 0.41904\nEpoch 11/100\n113/113 [==============================] - 53s 473ms/step - loss: 0.3128 - accuracy: 0.6122 - val_loss: 0.7087 - val_accuracy: 0.4164\n\nEpoch 00011: val_accuracy did not improve from 0.41904\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001.\nEpoch 12/100\n113/113 [==============================] - 54s 474ms/step - loss: 0.2836 - accuracy: 0.6418 - val_loss: 0.7113 - val_accuracy: 0.4189\n\nEpoch 00012: val_accuracy did not improve from 0.41904\nEpoch 13/100\n113/113 [==============================] - 53s 473ms/step - loss: 0.2682 - accuracy: 0.6599 - val_loss: 0.7179 - val_accuracy: 0.4181\n\nEpoch 00013: val_accuracy did not improve from 0.41904\nEpoch 14/100\n113/113 [==============================] - 53s 473ms/step - loss: 0.2554 - accuracy: 0.6746 - val_loss: 0.7245 - val_accuracy: 0.4180\n\nEpoch 00014: val_accuracy did not improve from 0.41904\nEpoch 00014: early stopping\n","output_type":"stream"},{"execution_count":204,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f9e6d1137d0>"},"metadata":{}}]},{"cell_type":"code","source":"epochs = 100  # This should be at least 30 for convergence\n\ntransformer.summary()\ntransformer.compile(\n    \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n)\ntransformer.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=cbs)","metadata":{"id":"H50DkdfyLyqt","outputId":"14b02f52-c376-4b58-9dab-288665275e71","execution":{"iopub.status.busy":"2021-06-08T02:23:20.904352Z","iopub.execute_input":"2021-06-08T02:23:20.904743Z","iopub.status.idle":"2021-06-08T02:39:48.287839Z","shell.execute_reply.started":"2021-06-08T02:23:20.904704Z","shell.execute_reply":"2021-06-08T02:39:48.287102Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Model: \"transformer\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_inputs (InputLayer)     [(None, None)]       0                                            \n__________________________________________________________________________________________________\npositional_embedding_4 (Positio (None, None, 300)    3964200     encoder_inputs[0][0]             \n__________________________________________________________________________________________________\ndecoder_inputs (InputLayer)     [(None, None)]       0                                            \n__________________________________________________________________________________________________\ntransformer_encoder_2 (Transfor (None, None, 300)    4119848     positional_embedding_4[0][0]     \n__________________________________________________________________________________________________\nmodel_5 (Functional)            (None, None, 20000)  19042948    decoder_inputs[0][0]             \n                                                                 transformer_encoder_2[0][0]      \n==================================================================================================\nTotal params: 27,126,996\nTrainable params: 27,126,996\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/100\n113/113 [==============================] - 59s 498ms/step - loss: 1.0497 - accuracy: 0.2615 - val_loss: 0.8023 - val_accuracy: 0.3430\n\nEpoch 00001: val_accuracy improved from -inf to 0.34302, saving model to ./pretrained_en/weights_adam.ckpt\nEpoch 2/100\n113/113 [==============================] - 54s 479ms/step - loss: 0.7741 - accuracy: 0.3561 - val_loss: 0.7480 - val_accuracy: 0.3737\n\nEpoch 00002: val_accuracy improved from 0.34302 to 0.37374, saving model to ./pretrained_en/weights_adam.ckpt\nEpoch 3/100\n113/113 [==============================] - 54s 480ms/step - loss: 0.6870 - accuracy: 0.3973 - val_loss: 0.7232 - val_accuracy: 0.3868\n\nEpoch 00003: val_accuracy improved from 0.37374 to 0.38684, saving model to ./pretrained_en/weights_adam.ckpt\nEpoch 4/100\n113/113 [==============================] - 54s 481ms/step - loss: 0.6143 - accuracy: 0.4313 - val_loss: 0.7174 - val_accuracy: 0.3919\n\nEpoch 00004: val_accuracy improved from 0.38684 to 0.39191, saving model to ./pretrained_en/weights_adam.ckpt\nEpoch 5/100\n113/113 [==============================] - 54s 480ms/step - loss: 0.5502 - accuracy: 0.4588 - val_loss: 0.7178 - val_accuracy: 0.3896\n\nEpoch 00005: val_accuracy did not improve from 0.39191\nEpoch 6/100\n113/113 [==============================] - 54s 479ms/step - loss: 0.4938 - accuracy: 0.4889 - val_loss: 0.7225 - val_accuracy: 0.4016\n\nEpoch 00006: val_accuracy improved from 0.39191 to 0.40165, saving model to ./pretrained_en/weights_adam.ckpt\nEpoch 7/100\n113/113 [==============================] - 54s 480ms/step - loss: 0.4389 - accuracy: 0.5204 - val_loss: 0.7294 - val_accuracy: 0.4006\n\nEpoch 00007: val_accuracy did not improve from 0.40165\nEpoch 8/100\n113/113 [==============================] - 54s 480ms/step - loss: 0.3882 - accuracy: 0.5550 - val_loss: 0.7288 - val_accuracy: 0.3982\n\nEpoch 00008: val_accuracy did not improve from 0.40165\n\nEpoch 00008: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\nEpoch 9/100\n113/113 [==============================] - 54s 480ms/step - loss: 0.3292 - accuracy: 0.6020 - val_loss: 0.7174 - val_accuracy: 0.4111\n\nEpoch 00009: val_accuracy improved from 0.40165 to 0.41113, saving model to ./pretrained_en/weights_adam.ckpt\nEpoch 10/100\n113/113 [==============================] - 54s 480ms/step - loss: 0.2778 - accuracy: 0.6564 - val_loss: 0.7329 - val_accuracy: 0.4113\n\nEpoch 00010: val_accuracy improved from 0.41113 to 0.41133, saving model to ./pretrained_en/weights_adam.ckpt\nEpoch 11/100\n113/113 [==============================] - 54s 482ms/step - loss: 0.2468 - accuracy: 0.6915 - val_loss: 0.7502 - val_accuracy: 0.4082\n\nEpoch 00011: val_accuracy did not improve from 0.41133\nEpoch 12/100\n113/113 [==============================] - 54s 481ms/step - loss: 0.2200 - accuracy: 0.7223 - val_loss: 0.7668 - val_accuracy: 0.4089\n\nEpoch 00012: val_accuracy did not improve from 0.41133\n\nEpoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001.\nEpoch 13/100\n113/113 [==============================] - 54s 480ms/step - loss: 0.1972 - accuracy: 0.7470 - val_loss: 0.7729 - val_accuracy: 0.4126\n\nEpoch 00013: val_accuracy improved from 0.41133 to 0.41265, saving model to ./pretrained_en/weights_adam.ckpt\nEpoch 14/100\n113/113 [==============================] - 54s 479ms/step - loss: 0.1835 - accuracy: 0.7640 - val_loss: 0.7813 - val_accuracy: 0.4117\n\nEpoch 00014: val_accuracy did not improve from 0.41265\nEpoch 15/100\n113/113 [==============================] - 54s 480ms/step - loss: 0.1723 - accuracy: 0.7791 - val_loss: 0.7897 - val_accuracy: 0.4097\n\nEpoch 00015: val_accuracy did not improve from 0.41265\nEpoch 16/100\n113/113 [==============================] - 54s 479ms/step - loss: 0.1636 - accuracy: 0.7895 - val_loss: 0.7982 - val_accuracy: 0.4074\n\nEpoch 00016: val_accuracy did not improve from 0.41265\nEpoch 17/100\n113/113 [==============================] - 54s 480ms/step - loss: 0.1551 - accuracy: 0.7997 - val_loss: 0.8071 - val_accuracy: 0.4075\n\nEpoch 00017: val_accuracy did not improve from 0.41265\nEpoch 18/100\n113/113 [==============================] - 54s 480ms/step - loss: 0.1479 - accuracy: 0.8098 - val_loss: 0.8159 - val_accuracy: 0.4061\n\nEpoch 00018: val_accuracy did not improve from 0.41265\nEpoch 00018: early stopping\n","output_type":"stream"},{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f9eab9aad10>"},"metadata":{}}]},{"cell_type":"code","source":"latest = tf.train.latest_checkpoint(googledrive_path)\ntransformer.load_weights(latest)","metadata":{"id":"j5Qvebl8FHsG","outputId":"409bb93b-6c20-4a05-d937-b01576015d44","execution":{"iopub.status.busy":"2021-06-08T02:39:58.377008Z","iopub.execute_input":"2021-06-08T02:39:58.377328Z","iopub.status.idle":"2021-06-08T02:39:58.713799Z","shell.execute_reply.started":"2021-06-08T02:39:58.377296Z","shell.execute_reply":"2021-06-08T02:39:58.712839Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa2c86f8210>"},"metadata":{}}]},{"cell_type":"code","source":"ar_vocab = ar_vectorization.get_vocabulary()\nar_index_lookup = dict(zip(range(len(ar_vocab)), ar_vocab))\nmax_decoded_sentence_length = sequence_length\n\n\ndef decode_sequence(input_sentence):\n    tokenized_input_sentence = eng_vectorization([input_sentence])\n    decoded_sentence = \"[start]\"\n    for i in range(max_decoded_sentence_length):\n        tokenized_target_sentence = ar_vectorization([decoded_sentence])[:, :-1]\n        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n\n        sampled_token_index = np.argmax(predictions[0, i, :])\n        sampled_token = ar_index_lookup[sampled_token_index]\n        decoded_sentence += \" \" + sampled_token\n\n        if sampled_token == \"[end]\":\n            break\n    return decoded_sentence\n\n\ntest_eng_texts = [pair[0] for pair in val_pairs]\nfor _ in range(30):\n    input_sentence = random.choice(test_eng_texts[:30])\n    translated = decode_sequence(input_sentence)\n    print(input_sentence, '\\n', translated)\n    print('*'*50)","metadata":{"id":"8447490b","outputId":"0579b30f-8902-4242-8ac0-574cfd8c53da","execution":{"iopub.status.busy":"2021-06-08T04:04:11.583186Z","iopub.execute_input":"2021-06-08T04:04:11.583522Z","iopub.status.idle":"2021-06-08T04:04:17.842227Z","shell.execute_reply.started":"2021-06-08T04:04:11.583490Z","shell.execute_reply":"2021-06-08T04:04:17.841483Z"},"trusted":true},"execution_count":205,"outputs":[{"name":"stdout","text":"This was originally just a water container. \n [start] هذه كانت ال حجرة سفينة فقط [UNK] [end]\n**************************************************\nRoom 1 4. Next to the solarium. \n [start] ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة [end]\n**************************************************\nMaybe not as thick as the ones that Joshua blew down with his trumpet. \n [start] ربما لا بين ال ثلج كما [UNK] [end]\n**************************************************\nRoom 1 4. Next to the solarium. \n [start] ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة ال حلقة [end]\n**************************************************\nYou're not Han Na, are you? \n [start] انت لست هان نا ، اليس كذلك ؟ [end]\n**************************************************\nI Won't Be Here,And- \n [start] لن اكون ساكون [end]\n**************************************************\nYou're not Han Na, are you? \n [start] انت لست هان نا ، اليس كذلك ؟ [end]\n**************************************************\nI'll keep my foot here, and you hit it whenever you can. \n [start] [UNK] على ال ان تذهب و [UNK] [end]\n**************************************************\nSo that is indeed what they're planning. \n [start] لذا ، هذا ال حقيقة انهم يقولوا ماذا ؟ [end]\n**************************************************\nI Won't Be Here,And- \n [start] لن اكون ساكون [end]\n**************************************************\nThat's large-format barrels, neutral oak. \n [start] ذلك سحر ال [UNK] ال سرو [end]\n**************************************************\nFather, come on. \n [start] ابي هيا [end]\n**************************************************\nYou're definitely not the Tony Stark I once knew. \n [start] انت متاكد انك لا توني ، ان [end]\n**************************************************\nThis was an office for ghosts? \n [start] لقد كنت هنا بسبب شبح [end]\n**************************************************\nThis was an office for ghosts? \n [start] لقد كنت هنا بسبب شبح [end]\n**************************************************\nYeah,Mr. Meade Meant A Lot To Me, \n [start] كلير ميد انا ، انت ، انا [end]\n**************************************************\nI'll keep my foot here, and you hit it whenever you can. \n [start] [UNK] على ال ان تذهب و [UNK] [end]\n**************************************************\nFind out what she's into, and then also be into it. \n [start] يبحث عنها و هي و هي ايضا [end]\n**************************************************\nKang Woo, are you having a hard time? \n [start] كانغ وو ، هل انت ايضا ؟ [end]\n**************************************************\nTarzan, don't. \n [start] ترازان لا [end]\n**************************************************\nI purposely didn't given it back to him because that's what I wanted. \n [start] لقد [UNK] ال ذي لم افعل ما هو [end]\n**************************************************\n- Later, perhaps. \n [start] ربما ربما [end]\n**************************************************\nThank you! \n [start] شكرا لك [end]\n**************************************************\nHoney! \n [start] عزيزتي [end]\n**************************************************\n-Let him have it! \n [start] [UNK] [end]\n**************************************************\nThis was an office for ghosts? \n [start] لقد كنت هنا بسبب شبح [end]\n**************************************************\n- Being confident without begging... \n [start] احيانا [end]\n**************************************************\nFind out what she's into, and then also be into it. \n [start] يبحث عنها و هي و هي ايضا [end]\n**************************************************\n- Bed 26, sir. \n [start] سرير رقم [UNK] [end]\n**************************************************\nThat's large-format barrels, neutral oak. \n [start] ذلك سحر ال [UNK] ال سرو [end]\n**************************************************\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_bleu():\n  \n  preds, src = [], []\n\n  with tqdm(total=len(val_pairs), position=0, leave=True) as pbar:\n    for en_sent, ar_sent in tqdm(val_pairs, position=0, leave=True):\n      translated = decode_sequence(en_sent)\n      preds.append(translated)\n      src.append(ar_sent)\n      pbar.update()\n\n    return src, preds\n    # print_scores(src, preds)\n\n","metadata":{"id":"p2i4SbVoP_Yz","execution":{"iopub.status.busy":"2021-06-08T02:40:58.148840Z","iopub.execute_input":"2021-06-08T02:40:58.149218Z","iopub.status.idle":"2021-06-08T02:40:58.155254Z","shell.execute_reply.started":"2021-06-08T02:40:58.149177Z","shell.execute_reply":"2021-06-08T02:40:58.154292Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"def print_scores(trgs, preds):\n    print('----- Bleu-n Scores -----')\n    print(\"1:\", corpus_bleu(trgs, preds, weights=[1.0/1.0])*100)\n    print(\"2:\", corpus_bleu(trgs, preds, weights=[1.0/2.0, 1.0/2.0])*100)\n    print(\"3:\", corpus_bleu(trgs, preds, weights=[1.0/3.0, 1.0/3.0, 1.0/3.0])*100)\n    print(\"4:\", corpus_bleu(trgs, preds)*100)\n    print('-'*25)","metadata":{"id":"A9uh1623AwUW","execution":{"iopub.status.busy":"2021-06-08T02:40:59.410199Z","iopub.execute_input":"2021-06-08T02:40:59.410504Z","iopub.status.idle":"2021-06-08T02:40:59.415944Z","shell.execute_reply.started":"2021-06-08T02:40:59.410474Z","shell.execute_reply":"2021-06-08T02:40:59.414990Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"src, preds = get_bleu()","metadata":{"id":"YaXlIeHdRGqi","outputId":"ee8a6fbf-2d72-4bc6-b65c-ce54f944723d","execution":{"iopub.status.busy":"2021-06-08T02:41:00.631949Z","iopub.execute_input":"2021-06-08T02:41:00.632276Z","iopub.status.idle":"2021-06-08T02:59:20.928004Z","shell.execute_reply.started":"2021-06-08T02:41:00.632247Z","shell.execute_reply":"2021-06-08T02:59:20.925932Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stderr","text":"100%|██████████| 5267/5267 [18:20<00:00,  4.79it/s]\n100%|██████████| 5267/5267 [18:20<00:00,  4.79it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu","metadata":{"id":"tSinG65pSGkC","execution":{"iopub.status.busy":"2021-06-08T02:59:20.929740Z","iopub.execute_input":"2021-06-08T02:59:20.930082Z","iopub.status.idle":"2021-06-08T02:59:20.934886Z","shell.execute_reply.started":"2021-06-08T02:59:20.930048Z","shell.execute_reply":"2021-06-08T02:59:20.933814Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"print_scores(preds, src)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T02:59:20.936277Z","iopub.execute_input":"2021-06-08T02:59:20.936757Z","iopub.status.idle":"2021-06-08T03:00:10.585162Z","shell.execute_reply.started":"2021-06-08T02:59:20.936723Z","shell.execute_reply":"2021-06-08T03:00:10.583379Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"----- Bleu-n Scores -----\n1: 40.14637653331428\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"},{"name":"stdout","text":"2: 63.3611683393814\n3: 73.77039652394956\n4: 79.59972885593355\n-------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"for _ in range(10):\n  i = random.randint(0, 500)\n  print(\"prediction:\", preds[i][7:-6])\n  print(\"source:\", src[i][7:-6])\n  print('_'*100)","metadata":{"id":"mBYxHDaET9ya","outputId":"b43e79a4-0bf6-4ad8-9b39-51d353de5dc4","execution":{"iopub.status.busy":"2021-06-08T03:00:17.962062Z","iopub.execute_input":"2021-06-08T03:00:17.962374Z","iopub.status.idle":"2021-06-08T03:00:17.973887Z","shell.execute_reply.started":"2021-06-08T03:00:17.962344Z","shell.execute_reply":"2021-06-08T03:00:17.971402Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"prediction:  اذا كان [UNK] على ال يدي\nsource:  لو وق بين يدى\n____________________________________________________________________________________________________\nprediction:  ماذا قلت ؟\nsource:  - ماذا قلت ؟\n____________________________________________________________________________________________________\nprediction:  يبدو انك [UNK]\nsource:  . واو .... رييس انت تكسب ال كثير من ال اموال\n____________________________________________________________________________________________________\nprediction:  لا ، لا ، لا\nsource:  لا يوجد رد\n____________________________________________________________________________________________________\nprediction:  هذه هي ال احذية لكن ، اعتقد انه في سريرك\nsource:  هذه امتعته ، لكن اعتقد هو في حجرته .\n____________________________________________________________________________________________________\nprediction:  لانى [UNK]\nsource:  #، هذا جزيي ال مفضل لانكم #\n____________________________________________________________________________________________________\nprediction:  اكره ال ناس ال اكره ال طلاب\nsource:  اكره متاعب ال فتيات\n____________________________________________________________________________________________________\nprediction:  الى ال كونت هناك واجب لابتهاج ال خبز ال خبز و تنفيس\nsource:  بالسجن ال ابدي ان تاكلي خبز ال حزن و ان تشربي ماء ال عذاب\n____________________________________________________________________________________________________\nprediction:  كل ال خروج من ال طريق\nsource:  حسنا ايها ال ناس ابتعدو من هنا\n____________________________________________________________________________________________________\nprediction:  لا افهم\nsource:  لست افهم\n____________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip translation_pre_both.zip ./pretrained_both/weights_adam.ckpt.data-00000-of-00001 ./pretrained_en/weights_adam.ckpt.index","metadata":{"execution":{"iopub.status.busy":"2021-06-08T04:06:15.256141Z","iopub.execute_input":"2021-06-08T04:06:15.256470Z","iopub.status.idle":"2021-06-08T04:06:31.744554Z","shell.execute_reply.started":"2021-06-08T04:06:15.256439Z","shell.execute_reply":"2021-06-08T04:06:31.743387Z"},"trusted":true},"execution_count":206,"outputs":[{"name":"stdout","text":"  adding: pretrained_both/weights_adam.ckpt.data-00000-of-00001 (deflated 9%)\n  adding: pretrained_en/weights_adam.ckpt.index (deflated 76%)\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'translation_pre_both.zip')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T04:06:37.795168Z","iopub.execute_input":"2021-06-08T04:06:37.795508Z","iopub.status.idle":"2021-06-08T04:06:37.803246Z","shell.execute_reply.started":"2021-06-08T04:06:37.795475Z","shell.execute_reply":"2021-06-08T04:06:37.802112Z"},"trusted":true},"execution_count":207,"outputs":[{"execution_count":207,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/translation_pre_both.zip","text/html":"<a href='translation_pre_both.zip' target='_blank'>translation_pre_both.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}