{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "simple transformer_other_dataset_adam_100words_2datasets_pretrained_en.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R53kjrYGpSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212290f5-7d1f-4eba-82b9-3cbdd499b486"
      },
      "source": [
        "!git clone https://github.com/moaaztaha/Arabic-English-Translation-Transformers"
      ],
      "id": "0R53kjrYGpSc",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Arabic-English-Translation-Transformers'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 39 (delta 13), reused 34 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (39/39), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9e97fa1"
      },
      "source": [
        "# modules\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "id": "e9e97fa1",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1710411f"
      },
      "source": [
        "### Data Preprocessing "
      ],
      "id": "1710411f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RNDMX9cizGW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "846a941e-f6c0-460b-8979-1e5d0ed0925a"
      },
      "source": [
        "en = pd.read_table('/content/Arabic-English-Translation-Transformers/data/eng/ac-test.en', delimiter='\\\\n', names=['en'])\n",
        "ar = pd.read_table('/content/Arabic-English-Translation-Transformers/data/ara/test.en_ref.ar', delimiter='\\\\n', names=['ar'])\n",
        "en['ar'] = ar['ar']\n",
        "df = en.copy()\n",
        "df.head()"
      ],
      "id": "1RNDMX9cizGW",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py:767: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return read_csv(**locals())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>ar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE COUNCIL OF THE EUROPEAN ECONOMIC COMMUNITY,</td>\n",
              "      <td>مجلس الجماعة الاقتصادية الأوروبية</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Whereas the adoption of a common transport pol...</td>\n",
              "      <td>حيث أن اعتماد سياسة نقل مشتركة تنطوي من بين أم...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Article 1</td>\n",
              "      <td>المادة 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3. The types of carriage listed in Annex II sh...</td>\n",
              "      <td>3. لا تخضع أنواع النقل المدرجة في الملحق الثان...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Member States shall inform the Commission of t...</td>\n",
              "      <td>تبلغ الدول الأعضاء المفوضية الأوروبية بالتدابي...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en                                                 ar\n",
              "0    THE COUNCIL OF THE EUROPEAN ECONOMIC COMMUNITY,                  مجلس الجماعة الاقتصادية الأوروبية\n",
              "1  Whereas the adoption of a common transport pol...  حيث أن اعتماد سياسة نقل مشتركة تنطوي من بين أم...\n",
              "2                                          Article 1                                           المادة 1\n",
              "3  3. The types of carriage listed in Annex II sh...  3. لا تخضع أنواع النقل المدرجة في الملحق الثان...\n",
              "4  Member States shall inform the Commission of t...  تبلغ الدول الأعضاء المفوضية الأوروبية بالتدابي..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be905b2c"
      },
      "source": [
        "text_pairs = []\n",
        "for idx, row in df.iterrows():\n",
        "    # split sentences\n",
        "    if '.' in row['en'] and '.' in row['ar'] and len(row['en'].split()) > 100:\n",
        "        en_sents = row['en'].split('.')\n",
        "        ar_sents = row['ar'].split('.')\n",
        "    \n",
        "        for en_sent, ar_sent in zip(en_sents, ar_sents):\n",
        "            ar_sent = \"[start] \" + ar_sent + \" [end]\"\n",
        "            text_pairs.append((en_sent, ar))\n",
        "    else:\n",
        "        en, ar = row['en'], row['ar']\n",
        "        ar = \"[start] \" + ar + \" [end]\"\n",
        "        text_pairs.append((en, ar))"
      ],
      "id": "be905b2c",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "296e4594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0047ae-9184-4447-a567-b0bc93418a60"
      },
      "source": [
        "for _ in range(2):\n",
        "    print(random.choice(text_pairs))"
      ],
      "id": "296e4594",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Whereas, in establishing maximum residue limits for residues of veterinary medicinal products in foodstuffs of animal origin, it is necessary to specify the animal species in which residues may be present, the levels which may be present in each of the relevant meat tissues obtained from the treated animal (target tissue) and the nature of the residue which is relevant for the monitoring of residues (marker residue);', '[start] حيث أنّه، ولدى تحديد الحدود القصوى لبقايا المنتجات الطبية البيطرية في المواد الغذائية الحيوانية المصدر، من الضروري تحديد الفصائل الحيوانية التي يمكن أن تتوفر فيها البقايا والمستويات التي يمكن أن تتوفر في كلّ من أنسجة اللحوم ذات الصلة والتي يتم الحصول عليها من الحيوان المُعالج (النسيج المستهدف) وطبيعة البقايا الضرورية لرصد البقايا (البقايا الدليلية)؛ [end]')\n",
            "('of 16 December 2002', '[start] بتاريخ 16 ديسمبر 2002 [end]')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6kRoro9iBOe",
        "outputId": "633d0433-3b07-4910-9976-af74c615320e"
      },
      "source": [
        "len(text_pairs)"
      ],
      "id": "o6kRoro9iBOe",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4262"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "c9H3kM4OiDWv",
        "outputId": "df9aa5b7-f2a4-4b02-9796-a9928ecee5fd"
      },
      "source": [
        "en = pd.read_table('/content/Arabic-English-Translation-Transformers/data/eng/ac-dev.en', delimiter='\\\\n', names=['en'])\n",
        "ar = pd.read_table('/content/Arabic-English-Translation-Transformers/data/ara/tune.en_ref.ar', delimiter='\\\\n', names=['ar'])\n",
        "#2725 to 3742\n",
        "ar.drop(ar.loc[2725:3742].index,inplace=True)\n",
        "#2720 to 3707\n",
        "en.drop(en.loc[2725:3742].index,inplace=True)\n",
        "en['ar'] = ar['ar']\n",
        "df = en.copy()\n",
        "df.head()"
      ],
      "id": "c9H3kM4OiDWv",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py:767: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return read_csv(**locals())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>ar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Having regard to the Treaty establishing the E...</td>\n",
              "      <td>مع الأخذ في الاعتبار المعاهدة التي أنشئت بموجب...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Whereas the progressive establishment of the c...</td>\n",
              "      <td>وحيث أنه لا يجب أن تواجه عملية الإنشاء التدريج...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1. Each Member State shall, by the end of 1962...</td>\n",
              "      <td>1. يتعيّن على كلّ دولة عضو بحلول نهاية العام 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4. The two Annexes to this Directive shall for...</td>\n",
              "      <td>4 يشكّل الملحقان المرفقان بهذا التوجيه جزءاً ل...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Article 3</td>\n",
              "      <td>المادة 3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en                                                 ar\n",
              "0  Having regard to the Treaty establishing the E...  مع الأخذ في الاعتبار المعاهدة التي أنشئت بموجب...\n",
              "1  Whereas the progressive establishment of the c...  وحيث أنه لا يجب أن تواجه عملية الإنشاء التدريج...\n",
              "2  1. Each Member State shall, by the end of 1962...  1. يتعيّن على كلّ دولة عضو بحلول نهاية العام 1...\n",
              "3  4. The two Annexes to this Directive shall for...  4 يشكّل الملحقان المرفقان بهذا التوجيه جزءاً ل...\n",
              "4                                          Article 3                                           المادة 3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEsz9VaiiNfw"
      },
      "source": [
        "for idx, row in df.iterrows():\n",
        "    # split sentences\n",
        "    if '.' in row['en'] and '.' in row['ar'] and len(row['en'].split()) > 100:\n",
        "        en_sents = row['en'].split('.')\n",
        "        ar_sents = row['ar'].split('.')\n",
        "    \n",
        "        for en_sent, ar_sent in zip(en_sents, ar_sents):\n",
        "            ar_sent = \"[start] \" + ar_sent + \" [end]\"\n",
        "            text_pairs.append((en_sent, ar))\n",
        "    else:\n",
        "        en, ar = row['en'], row['ar']\n",
        "        ar = \"[start] \" + ar + \" [end]\"\n",
        "        text_pairs.append((en, ar))"
      ],
      "id": "yEsz9VaiiNfw",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBeN07JJRt_y",
        "outputId": "2719db59-ad03-413d-fdd9-d8f72401dc4b"
      },
      "source": [
        "random.choice(text_pairs)"
      ],
      "id": "qBeN07JJRt_y",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Whereas, through the protection of potato and tomato cultivation against such harmful organisms, not only should productive capacity be maintained but agricultural productivity should also be increased;',\n",
              " '[start] حيث إنه، من خلال حماية زراعة البطاطس والطماطم من هذه العضويات الضارة، فلا يجب الحفاظ على القدرة الإنتاجية فحسب، بل يجب زيادة الإنتاجية الزراعية أيضًا؛ [end]')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1283f6f"
      },
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) -  num_val_samples\n",
        "train_pairs = text_pairs[: num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples: num_train_samples + num_val_samples]"
      ],
      "id": "c1283f6f",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7a1f8cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01d00a6c-9078-4aa6-be9b-cc06390f5855"
      },
      "source": [
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")"
      ],
      "id": "a7a1f8cd",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7421 total pairs\n",
            "6308 training pairs\n",
            "1113 validation pairs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5f6d84e"
      },
      "source": [
        "#### Vectorizing the text data "
      ],
      "id": "d5f6d84e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "487ed66f"
      },
      "source": [
        "strip_chars = string.punctuation\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "\n",
        "# vocab_size = 10000\n",
        "sequence_length = 50\n",
        "batch_size = 265\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    return tf.strings.regex_replace(input_string, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "            # max_tokens=vocab_size, \n",
        "            output_mode='int', \n",
        "            output_sequence_length=sequence_length)\n",
        "\n",
        "ar_vectorization = TextVectorization(\n",
        "    # max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization)\n",
        "\n",
        "eng_texts = [pair[0] for pair in text_pairs]\n",
        "ar_texts = [pair[1] for pair in text_pairs]\n",
        "eng_vectorization.adapt(eng_texts)\n",
        "ar_vectorization.adapt(ar_texts)"
      ],
      "id": "487ed66f",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5qiqjOWdVz1"
      },
      "source": [
        "def format_dataset(eng, ar):\n",
        "    eng = eng_vectorization(eng)\n",
        "    ar = ar_vectorization(ar)\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": ar[:, :-1],}, ar[:, 1:])\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, ar_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    ar_texts = list(ar_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ar_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()"
      ],
      "id": "V5qiqjOWdVz1",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a3ed140"
      },
      "source": [
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "id": "7a3ed140",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3902789f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca66e4a7-5b1a-4c43-99da-c321c86231c2"
      },
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "id": "3902789f",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (265, 50)\n",
            "inputs[\"decoder_inputs\"].shape: (265, 50)\n",
            "targets.shape: (265, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fa0936c"
      },
      "source": [
        "### Building the Model "
      ],
      "id": "4fa0936c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3baf452"
      },
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "      config = super().get_config().copy()\n",
        "      config.update({\n",
        "          'embed_dim': self.embed_dim,\n",
        "          'dense_dim': self.dense_dim,\n",
        "          'num_heads': self.num_heads,\n",
        "      })\n",
        "      return config\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, pretrained=False, weights=False, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        if not pretrained:\n",
        "          self.token_embeddings = layers.Embedding(\n",
        "              input_dim=vocab_size, output_dim=embed_dim\n",
        "          )\n",
        "        else:\n",
        "          # pre-trained\n",
        "          self.token_embeddings = layers.Embedding(\n",
        "              input_dim=vocab_size, output_dim=embed_dim, weights=[weights]\n",
        "          ) \n",
        "\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "      \n",
        "    def get_config(self):\n",
        "\n",
        "      config = super().get_config().copy()\n",
        "      config.update({\n",
        "      'sequence_length': self.sequence_length,\n",
        "      'vocab_size': self.vocab_size,\n",
        "      'embed_dim': self.embed_dim,\n",
        "      })\n",
        "      return config\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "      config = super().get_config().copy()\n",
        "      config.update({\n",
        "      'embed_dim': self.embed_dim,\n",
        "      'latent_dim': self.latent_dim,\n",
        "      'num_heads': self.num_heads,\n",
        "      })\n",
        "      return config\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ],
      "id": "b3baf452",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpXVu3eA_b9P"
      },
      "source": [
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# !unzip -q glove.6B.zip"
      ],
      "id": "fpXVu3eA_b9P",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afjYy3g6BM2K",
        "outputId": "e32988e0-c411-403e-c96b-f847eb6a7677"
      },
      "source": [
        "import os\n",
        "path_to_glove_file = os.path.join(\n",
        "    os.path.expanduser(\"~\"), \"/content/glove.6B.300d.txt\"\n",
        ")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "id": "afjYy3g6BM2K",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRNRUzOCtccc"
      },
      "source": [
        "vocab = eng_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocab, range(len(vocab))))"
      ],
      "id": "XRNRUzOCtccc",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_rOhjwPuqkN",
        "outputId": "39a1e206-2234-4d03-c529-7f0747d3da4e"
      },
      "source": [
        "num_tokens = len(vocab)\n",
        "embedding_dim = 300\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        embedding_matrix[i] = np.random.uniform(-.1, .1, size=(embedding_dim))\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "id": "o_rOhjwPuqkN",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 6455 words (1522 misses)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWvsoAzszKiS",
        "outputId": "799a4dc8-b70b-4246-83b0-17863d424fcf"
      },
      "source": [
        "num_tokens"
      ],
      "id": "XWvsoAzszKiS",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcFB7h_o0JZC",
        "outputId": "d4ace499-296d-4f0e-897b-1f8ec61d9705"
      },
      "source": [
        "len(vocab)"
      ],
      "id": "FcFB7h_o0JZC",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0rA0C4s1OVW"
      },
      "source": [
        "ar_vocab_size = len(ar_vectorization.get_vocabulary())"
      ],
      "id": "U0rA0C4s1OVW",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04c57e1e"
      },
      "source": [
        "embed_dim = 300\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, num_tokens, embed_dim, pretrained=True, weights=embedding_matrix)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, ar_vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(ar_vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "id": "04c57e1e",
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt9sp6Yrb4pE"
      },
      "source": [
        "googledrive_path = '/content/drive/MyDrive/Transformers/pretrained_en_lrdecay'"
      ],
      "id": "vt9sp6Yrb4pE",
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqmaEQ94kyB9"
      },
      "source": [
        "from keras import callbacks\n",
        "early_stopping_cb = callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=True)\n",
        "checkpoint_cb = callbacks.ModelCheckpoint(googledrive_path+'/weights_adam.ckpt', monitor='val_accuracy', save_weights_only=True,verbose=True, save_best_only=True)\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=googledrive_path+\"/logs\")\n",
        "lr_schr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=True, factor=0.3, min_lr=0.0001)\n",
        "cbs = [early_stopping_cb, checkpoint_cb, tensorboard_callback, lr_schr]"
      ],
      "id": "wqmaEQ94kyB9",
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H50DkdfyLyqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38d896fc-e0b2-4237-c775-e9d161096734"
      },
      "source": [
        "epochs = 100  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=cbs)"
      ],
      "id": "H50DkdfyLyqt",
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "positional_embedding_8 (Positio (None, None, 300)    2408100     encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder_4 (Transfor (None, None, 300)    4119848     positional_embedding_8[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "model_9 (Functional)            (None, None, 18492)  18136640    decoder_inputs[0][0]             \n",
            "                                                                 transformer_encoder_4[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 24,664,588\n",
            "Trainable params: 24,664,588\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 21s 784ms/step - loss: 3.4336 - accuracy: 0.0915 - val_loss: 3.0071 - val_accuracy: 0.1348\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.13484, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 17s 726ms/step - loss: 2.8276 - accuracy: 0.1597 - val_loss: 2.7008 - val_accuracy: 0.2002\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.13484 to 0.20020, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 17s 708ms/step - loss: 2.4286 - accuracy: 0.2404 - val_loss: 2.4519 - val_accuracy: 0.2538\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.20020 to 0.25383, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 17s 703ms/step - loss: 2.1154 - accuracy: 0.2990 - val_loss: 2.3153 - val_accuracy: 0.2873\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.25383 to 0.28728, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 17s 711ms/step - loss: 1.8815 - accuracy: 0.3456 - val_loss: 2.2306 - val_accuracy: 0.3063\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.28728 to 0.30629, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 17s 716ms/step - loss: 1.6835 - accuracy: 0.3905 - val_loss: 2.1766 - val_accuracy: 0.3224\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.30629 to 0.32243, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 17s 716ms/step - loss: 1.5152 - accuracy: 0.4309 - val_loss: 2.1471 - val_accuracy: 0.3335\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.32243 to 0.33346, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 17s 712ms/step - loss: 1.3637 - accuracy: 0.4650 - val_loss: 2.1259 - val_accuracy: 0.3408\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.33346 to 0.34078, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 17s 713ms/step - loss: 1.2266 - accuracy: 0.4954 - val_loss: 2.1041 - val_accuracy: 0.3463\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.34078 to 0.34631, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 17s 713ms/step - loss: 1.1060 - accuracy: 0.5227 - val_loss: 2.1005 - val_accuracy: 0.3554\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.34631 to 0.35543, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 17s 717ms/step - loss: 0.9892 - accuracy: 0.5555 - val_loss: 2.1178 - val_accuracy: 0.3520\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.35543\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 17s 710ms/step - loss: 0.8871 - accuracy: 0.5873 - val_loss: 2.1144 - val_accuracy: 0.3595\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.35543 to 0.35946, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 17s 715ms/step - loss: 0.7906 - accuracy: 0.6245 - val_loss: 2.1428 - val_accuracy: 0.3617\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.35946 to 0.36167, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 17s 715ms/step - loss: 0.7037 - accuracy: 0.6591 - val_loss: 2.1588 - val_accuracy: 0.3640\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.36167 to 0.36404, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 17s 710ms/step - loss: 0.6276 - accuracy: 0.6922 - val_loss: 2.1928 - val_accuracy: 0.3639\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.36404\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 17s 715ms/step - loss: 0.5628 - accuracy: 0.7208 - val_loss: 2.2013 - val_accuracy: 0.3657\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.36404 to 0.36570, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 17s 712ms/step - loss: 0.4990 - accuracy: 0.7517 - val_loss: 2.2260 - val_accuracy: 0.3667\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.36570 to 0.36670, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 17s 717ms/step - loss: 0.4350 - accuracy: 0.7821 - val_loss: 2.3003 - val_accuracy: 0.3699\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.36670 to 0.36990, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 17s 715ms/step - loss: 0.3785 - accuracy: 0.8080 - val_loss: 2.2763 - val_accuracy: 0.3683\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.36990\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 17s 713ms/step - loss: 0.3186 - accuracy: 0.8400 - val_loss: 2.3070 - val_accuracy: 0.3736\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.36990 to 0.37361, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 17s 710ms/step - loss: 0.2699 - accuracy: 0.8650 - val_loss: 2.3384 - val_accuracy: 0.3661\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.37361\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 17s 712ms/step - loss: 0.2354 - accuracy: 0.8837 - val_loss: 2.3689 - val_accuracy: 0.3673\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.37361\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 17s 714ms/step - loss: 0.1839 - accuracy: 0.9127 - val_loss: 2.3611 - val_accuracy: 0.3795\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.37361 to 0.37951, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 17s 708ms/step - loss: 0.1406 - accuracy: 0.9365 - val_loss: 2.3657 - val_accuracy: 0.3798\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.37951 to 0.37976, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 17s 710ms/step - loss: 0.1202 - accuracy: 0.9495 - val_loss: 2.3821 - val_accuracy: 0.3792\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.37976\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 17s 712ms/step - loss: 0.1078 - accuracy: 0.9565 - val_loss: 2.3909 - val_accuracy: 0.3791\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.37976\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 17s 715ms/step - loss: 0.0977 - accuracy: 0.9620 - val_loss: 2.3956 - val_accuracy: 0.3811\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.37976 to 0.38105, saving model to /content/drive/MyDrive/Transformers/pretrained_en_lrdecay/weights_adam.ckpt\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 17s 717ms/step - loss: 0.0925 - accuracy: 0.9645 - val_loss: 2.4003 - val_accuracy: 0.3807\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.38105\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 17s 707ms/step - loss: 0.0900 - accuracy: 0.9659 - val_loss: 2.4044 - val_accuracy: 0.3805\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.38105\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 17s 710ms/step - loss: 0.0864 - accuracy: 0.9678 - val_loss: 2.4085 - val_accuracy: 0.3796\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.38105\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 17s 717ms/step - loss: 0.0842 - accuracy: 0.9683 - val_loss: 2.4133 - val_accuracy: 0.3802\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.38105\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 17s 711ms/step - loss: 0.0815 - accuracy: 0.9698 - val_loss: 2.4167 - val_accuracy: 0.3798\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.38105\n",
            "Epoch 00032: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efbe830c350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Qvebl8FHsG",
        "outputId": "409bb93b-6c20-4a05-d937-b01576015d44"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(googledrive_path)\n",
        "transformer.load_weights(latest)"
      ],
      "id": "j5Qvebl8FHsG",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7efc93e21a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8447490b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0579b30f-8902-4242-8ac0-574cfd8c53da"
      },
      "source": [
        "ar_vocab = ar_vectorization.get_vocabulary()\n",
        "ar_index_lookup = dict(zip(range(len(ar_vocab)), ar_vocab))\n",
        "max_decoded_sentence_length = sequence_length\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = ar_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = ar_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in val_pairs]\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts[:30])\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(input_sentence, '\\n', translated)\n",
        "    print('*'*50)"
      ],
      "id": "8447490b",
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article 1 \n",
            " [start] المادة 1 [end]\n",
            "**************************************************\n",
            "Having regard to the proposal from the Commission; \n",
            " [start] مع الأخذ في الاعتبار الاقتراح الصادر عن المفوضية الأوروبية، [end]\n",
            "**************************************************\n",
            "Before publication as provided for in paragraphs 2 and 4 and registration as provided for in paragraph 3, the Commission may request the opinion of the Committee provided for in Article 15. \n",
            " [start] قبل المادة 9 [end]\n",
            "**************************************************\n",
            "The representative of the Commission shall submit to the Committee a draft of the measures to be taken \n",
            " [start] 3 التكيف مع التقدم التقني في أساليب التحليل الكمي المنصوص عليها في الملحق II يجب أن تتلاءم مع الإجراءات المحددة في المادة 6 [end]\n",
            "**************************************************\n",
            "2. The measures referred to in the second indent of paragraph 1 shall apply until the substance is listed in Annex I or until a decision not to list it has been taken in accordance with the procedure laid down in Article 29. \n",
            " [start] 2 يجب اتخاذ التدابير المشار إليها في الفقرة الفرعية الثانية من المادة 1 في المادة 2 [end]\n",
            "**************************************************\n",
            "Article 2 \n",
            " [start] المادة 2 [end]\n",
            "**************************************************\n",
            "3. The measures decided upon by the Commission may be referred to the Council by any Member State within three working days following the day on which they were communicated. The Council shall meet without delay. It may by a qualified majority amend or repeal the measures in question. \n",
            " [start] 3 لا يجب اتخاذ التدابير المناسبة حتى نهاية فترة قرار المفوضية الأوروبية أو لم يكن هؤلاء الأشخاص المهنيين المشار إليها في ما إذا رأت الهيئة على الفور من قبل الأغلبية المؤهلة [end]\n",
            "**************************************************\n",
            "Article 7 \n",
            " [start] المادة 7 [end]\n",
            "**************************************************\n",
            "2. The measures referred to in the second indent of paragraph 1 shall apply until the substance is listed in Annex I or until a decision not to list it has been taken in accordance with the procedure laid down in Article 29. \n",
            " [start] 2 يجب اتخاذ التدابير المشار إليها في الفقرة الفرعية الثانية من المادة 1 في المادة 2 [end]\n",
            "**************************************************\n",
            "- security features. \n",
            " [start] يتخذ جميع [end]\n",
            "**************************************************\n",
            "Member States shall ensure that employees' representatives, when carrying out their functions, enjoy adequate protection and guarantees to enable them to perform properly the duties which have been assigned to them. \n",
            " [start] يجب أن تضمن الدول الأعضاء أن يتمتع الأشخاص الذين يقررون أهلية الحصول على الإذن لبدء الأعمال [end]\n",
            "**************************************************\n",
            ">TABLE> \n",
            " [start] الجدول [end]\n",
            "**************************************************\n",
            "Having regard to the opinion of the Economic and Social Committee (2), \n",
            " [start] مع الأخذ في الاعتبار الرأي الصادر عن اللجنة الاقتصادية والاجتماعية 2؛ [end]\n",
            "**************************************************\n",
            "Article 5 \n",
            " [start] المادة 5 [end]\n",
            "**************************************************\n",
            "3. To qualify under the tariff quota covered by serial No 09.0003, the following must be presented: \n",
            " [start] 3 بخصوص الموافقة على نوع الآلية عندما تُلاحظ أي فروقات بين خصائصها والتفاصيل الواردة في شهادة الموافقة على النوع وأو وثيقة المعلومات، وعندما لا تكون الدولة العضو، التي منحت الموافقة على نوع الآلية، قد شرعت هذه الفروقات بموجب المادة 6 2 أو 3 ولا تعتبر الآلية مخالفة للنوع المعتمد عندما\n",
            "**************************************************\n",
            "2. The measures referred to in the second indent of paragraph 1 shall apply until the substance is listed in Annex I or until a decision not to list it has been taken in accordance with the procedure laid down in Article 29. \n",
            " [start] 2 يجب اتخاذ التدابير المشار إليها في الفقرة الفرعية الثانية من المادة 1 في المادة 2 [end]\n",
            "**************************************************\n",
            "THE COMMISSION OF THE EUROPEAN COMMUNITIES, \n",
            " [start] مفوضية المجموعات الأوروبية، [end]\n",
            "**************************************************\n",
            "Before publication as provided for in paragraphs 2 and 4 and registration as provided for in paragraph 3, the Commission may request the opinion of the Committee provided for in Article 15. \n",
            " [start] قبل المادة 9 [end]\n",
            "**************************************************\n",
            "- instruments referred to in Article 16(3) of Directive 73/239/EEC, \n",
            " [start] الأدوات المشار إليها في المادة 18، و 2؛ [end]\n",
            "**************************************************\n",
            "Having regard to the Opinion of the European Parliament; \n",
            " [start] مع الأخذ في الاعتبار الرأي الصادر عن البرلمان الأوروبي 2، [end]\n",
            "**************************************************\n",
            ">TABLE> \n",
            " [start] الجدول [end]\n",
            "**************************************************\n",
            "The representative of the Commission shall submit to the Committee a draft of the measures to be taken \n",
            " [start] 3 التكيف مع التقدم التقني في أساليب التحليل الكمي المنصوص عليها في الملحق II يجب أن تتلاءم مع الإجراءات المحددة في المادة 6 [end]\n",
            "**************************************************\n",
            "- the degree of overfishing, \n",
            " [start] شهادة الدكتوراه في الصيدلة التي تمنحها الجامعات؛ [end]\n",
            "**************************************************\n",
            "Article 1 \n",
            " [start] المادة 1 [end]\n",
            "**************************************************\n",
            "Article 2 \n",
            " [start] المادة 2 [end]\n",
            "**************************************************\n",
            "Having regard to the Treaty establishing the European Economic Community, and in particular Article 99 thereof, \n",
            " [start] مع الأخذ في الاعتبار المعاهدة التي أنشئت بموجبها الجماعة الاقتصادية الأوروبية وبالتحديد المادة 100 منها؛ [end]\n",
            "**************************************************\n",
            "Article 7 \n",
            " [start] المادة 7 [end]\n",
            "**************************************************\n",
            "(c) the technical action plan for the following year; \n",
            " [start] ج الظروف الخاصة بصندوق الحصص في إطار عمل عام [end]\n",
            "**************************************************\n",
            "The representative of the Commission shall submit to the Committee a draft of the measures to be taken \n",
            " [start] 3 التكيف مع التقدم التقني في أساليب التحليل الكمي المنصوص عليها في الملحق II يجب أن تتلاءم مع الإجراءات المحددة في المادة 6 [end]\n",
            "**************************************************\n",
            "Before publication as provided for in paragraphs 2 and 4 and registration as provided for in paragraph 3, the Commission may request the opinion of the Committee provided for in Article 15. \n",
            " [start] قبل المادة 9 [end]\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2i4SbVoP_Yz"
      },
      "source": [
        "def get_bleu():\n",
        "  \n",
        "  preds, src = [], []\n",
        "\n",
        "  with tqdm(total=len(val_pairs), position=0, leave=True) as pbar:\n",
        "    for en_sent, ar_sent in tqdm(val_pairs, position=0, leave=True):\n",
        "      translated = decode_sequence(en_sent)\n",
        "      preds.append(translated)\n",
        "      src.append(ar_sent)\n",
        "      pbar.update()\n",
        "\n",
        "    return src, preds\n",
        "    # print_scores(src, preds)\n",
        "\n"
      ],
      "id": "p2i4SbVoP_Yz",
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9uh1623AwUW"
      },
      "source": [
        "def print_scores(trgs, preds):\n",
        "    print('----- Bleu-n Scores -----')\n",
        "    print(\"1:\", corpus_bleu(trgs, preds, weights=[1.0/1.0])*100)\n",
        "    print(\"2:\", corpus_bleu(trgs, preds, weights=[1.0/2.0, 1.0/2.0])*100)\n",
        "    print(\"3:\", corpus_bleu(trgs, preds, weights=[1.0/3.0, 1.0/3.0, 1.0/3.0])*100)\n",
        "    print(\"4:\", corpus_bleu(trgs, preds)*100)\n",
        "    print('-'*25)"
      ],
      "id": "A9uh1623AwUW",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaXlIeHdRGqi",
        "outputId": "ee8a6fbf-2d72-4bc6-b65c-ce54f944723d"
      },
      "source": [
        "src, preds = get_bleu()"
      ],
      "id": "YaXlIeHdRGqi",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1113/1113 [10:59<00:00,  1.69it/s]\n",
            "100%|██████████| 1113/1113 [10:59<00:00,  1.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSinG65pSGkC"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "id": "tSinG65pSGkC",
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEfbrEOtBKSk",
        "outputId": "8f89b268-946b-4cf4-e58d-38b60bebcbef"
      },
      "source": [
        "print_scores(preds, src)"
      ],
      "id": "hEfbrEOtBKSk",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Bleu-n Scores -----\n",
            "1: 19.884332149891485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2: 44.59185144159355\n",
            "3: 58.3673984448545\n",
            "4: 66.77713039775935\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBYxHDaET9ya",
        "outputId": "b43e79a4-0bf6-4ad8-9b39-51d353de5dc4"
      },
      "source": [
        "for _ in range(10):\n",
        "  i = random.randint(0, 500)\n",
        "  print(\"prediction:\", preds[i][7:-6])\n",
        "  print(\"source:\", src[i][7:-6])\n",
        "  print('_'*100)"
      ],
      "id": "mBYxHDaET9ya",
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction:  المادة 1\n",
            "source:  المادة 1\n",
            "____________________________________________________________________________________________________\n",
            "prediction:  ب يجوز أن تستخدم المنتجات الوحيدة التي تتألف من قبل السلطة المختصة في إطار برنامج معتمد لذلك من تلك البيانات وقابليتها للمقارنة؛\n",
            "source:  (ب) يشغلها شخص مستعد لمسك محاسبة الحيازة الزراعية وقادر على القيام بها، ومستعد لوضع بيانات المحاسبة لحيازته الزراعية في تصرف المفوضية الأوروبية؛\n",
            "____________________________________________________________________________________________________\n",
            "prediction:  مع الأخذ في الاعتبار الرأي الصادر عن اللجنة الاقتصادية والاجتماعية 2؛\n",
            "source:  مع الأخذ في الاعتبار الرأي الصادر عن اللجنة الاقتصادية والاجتماعية (2)،\n",
            "____________________________________________________________________________________________________\n",
            "prediction:  الفصل الخامس\n",
            "source:  الفصل الخامس\n",
            "____________________________________________________________________________________________________\n",
            "prediction:  يجب أن تمتثل للمتطلبات المنصوص عليها في الملحق 5 ما يلي\n",
            "source:  بموجب الشروط المنصوص عليها في الملحق، تتحمل المفوضية تكلفة ما يلي:\n",
            "____________________________________________________________________________________________________\n",
            "prediction:  2 حيث ووفقاً للشروط التي تُطبق الفقرة 1 في حالة عدم التقيد بالفقرة 1 ب وعند الضرورة، يتم فيها قبول أعضاء هذه الحالة، يجوز للهيئة تقديم المساهمات لهذا النظام خلال شخص يعمل باسمه الخاص بهذا النظام خلال فترة تعيينه في دولة عضو\n",
            "source:  2. حيث عملا بالفقرة 1، وباستمرار العمل بمساهمات نظام التقاعد التكميلي في إحدى الدول الأعضاء المساهمات، يعفى صاحب العمل والعامل، عند الاقتضاء، من أي التزام بالمساهمة في نظام التقاعد التكميلي في أي دولة عضو أخرى.\n",
            "____________________________________________________________________________________________________\n",
            "prediction:  مع الأخذ في الاعتبار الرأي الصادر عن اللجنة الاقتصادية والاجتماعية 2؛\n",
            "source:  مع الأخذ في الاعتبار الرأي الصادر عن اللجنة الاقتصادية والاجتماعية (2)،\n",
            "____________________________________________________________________________________________________\n",
            "prediction:  توجيه المجلس رقم 9277 المؤرخ في 14 تشرين الأول 1993 حول تثبيت المستويات القصوى المؤقتة للمتبقيات من ألياف النسيج الثنائي 4 و5 و6، غير كافية، قد تؤثر ذه المسألة على النحو المعدل أخيراً بواسطة التوجيه ‎90642EEC\n",
            "source:  توجيه المجلس رقم 93/41/EEC بتاريخ 14 يونيو/حزيران 1993 الذي أبطل التوجيه رقم 87/22/EEC بشأن تنسيق التدابير الوطنية المتعلقة بطرح منتجات طبية ذات التكنولوجيا العالية في السوق، وبخاصة تلك المشتقة من التكنولوجيا الحيوية\n",
            "____________________________________________________________________________________________________\n",
            "prediction:  في حالة عدم الإخلال بأحكام الفقرة 3، لا يوجد بها من الدول الأعضاء المنتجات المخصصة للاستهلاك البشري وفقًا للمادة 4 من قِبل الإدارات الفرنسية ما يتعلق بتراخيص تسويق المنتجات المسحوبة من قِبل منظمة المنتجين وتحديد\n",
            "source:  في الملخص الإحصائي للمخزون المنصوص عليه في المادة 4، يتعين حساب المنتجات المُجهّزة وفقًا للحمولة الفعلية بالطن؛ ويتعين حساب النفط الخام والمنتجات الوسيطة:\n",
            "____________________________________________________________________________________________________\n",
            "prediction:  1 التي تتم إضافة إلى حد تغييرها لعقد\n",
            "source:  1. يجب حماية الأسماء المسجلة من:\n",
            "____________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}