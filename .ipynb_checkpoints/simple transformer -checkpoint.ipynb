{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e97fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1710411f",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be905b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = Path('ara_eng.txt')\n",
    "\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "text_pairs = []\n",
    "for line in lines[:-1]:\n",
    "    eng, ar = line.split('\\t')\n",
    "    ar = \"[start] \" + ar + \" [end]\"\n",
    "    text_pairs.append((eng, ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "296e4594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the blogger also asks.', '[start] سالت المدونة ايضا [end]')\n",
      "('My upper right wisdom tooth hurts.', '[start] يؤلمني سن العقل في أعلى يمين أسناني. [end]')\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "967b34a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('you will also find links to some free web based platforms to create and save your creations in the week prior to international mother language day we ll be sharing retweeting and liking contributions from around the world and featuring some of our favorites here on rising voices.',\n",
       " '[start] ستجد ايضا روابط لمجموعة من منصات ابداع الميم المجانية لمساعدتك على ابتكار وحفظ ما تنتجه خلال الشهر السابق لليوم العالمي للغة الام سنواصل تعزيز الفكرة من خلال نشر واعادة تغريد المشاركات من جميع انحاء العالم وتخصيص مساحة لتلك المفضلة لدينا هنا على الاصوات الصاعدة [end]')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pairs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1283f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[: num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples: num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7a1f8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24638 total pairs\n",
      "17248 training pairs\n",
      "3695 validation pairs\n",
      "3695 test pairs\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f6d84e",
   "metadata": {},
   "source": [
    "#### Vectorizing the text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "487ed66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "batch_size = 64\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "eng_vectorization = TextVectorization(\n",
    "            max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_length)\n",
    "\n",
    "ar_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization)\n",
    "\n",
    "train_eng_texts = [pair[0] for pair in train_pairs]\n",
    "train_ar_texts = [pair[1] for pair in train_pairs]\n",
    "eng_vectorization.adapt(train_eng_texts)\n",
    "ar_vectorization.adapt(train_ar_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ca539c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(eng, ar):\n",
    "    eng = eng_vectorization(eng)\n",
    "    ar = ar_vectorization(ar)\n",
    "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": ar[:, :-1],}, ar[:, 1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae7f2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(pairs):\n",
    "    eng_texts, ar_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    ar_texts = list(ar_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ar_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a3ed140",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3902789f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
      "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa0936c",
   "metadata": {},
   "source": [
    "### Building the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b3baf452",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04c57e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "920565e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positional_embedding_2 (Positio (None, None, 256)    3845120     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_1 (Transfor (None, None, 256)    3155456     positional_embedding_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, None, 15000)  12959640    decoder_inputs[0][0]             \n",
      "                                                                 transformer_encoder_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 19,960,216\n",
      "Trainable params: 19,960,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "270/270 [==============================] - 811s 3s/step - loss: 3.9631 - accuracy: 0.1917 - val_loss: 3.3963 - val_accuracy: 0.2755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5d2535aef0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1  # This should be at least 30 for convergence\n",
    "\n",
    "transformer.summary()\n",
    "transformer.compile(\n",
    "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8447490b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You might want to talk to Tom. [start] [UNK] [UNK] [UNK] [end]\n",
      "two step verification in egypt strength or weakness for online security global voices advox. [start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] الاصوات الاصوات الاصوات [end]\n",
      "We appreciate your help. [start] [UNK] [UNK] [end]\n",
      "I'll call you every night. [start] [UNK] [UNK] [end]\n",
      "I am going to do my homework when I get home this afternoon. [start] [UNK] [UNK] [UNK] [UNK] [end]\n",
      "lisarowan google s olympic graphic today is a luger intentional or had been planned don t know whether to like the tribute or hate the irony. [start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "part and. [start] [UNK] الاصوات العالمية [end]\n",
      "on sunday may the gay pride festival took place in the capital city of san jose mauricio rojas es made a video showing the highlights of the event including music vendor stands dancing and speeches. [start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "the legal community has applauded the ruling ko but the damage may be difficult to undo. [start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [end]\n",
      "This is my father's house. [start] [UNK] [UNK] [end]\n",
      "amidsts all the congratulations and mabhrooks tallg was quick to point out that qatar now has to compete in round in order to qualify for the football world cup in south africa. [start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "Let's sing and dance. [start] [UNK] [UNK] [end]\n",
      "How can I help you? [start] [UNK] [UNK] [end]\n",
      "This is a present for you. [start] [UNK] [UNK] [end]\n",
      "I will give you this book. [start] [UNK] [UNK] [UNK] [end]\n",
      "I want to go home. [start] أنا [UNK] [end]\n",
      "cyberela naturally my social security can t cover my treatments hemangioma sufferers in greece are doomed. [start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [end]\n",
      "play your part in music history and join the youtube symphony orchestra you just need to upload two videos your contribution to the tan dun piece and a general audition video. [start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "What's happening? [start] [UNK] [end]\n",
      "She lives in comfort. [start] [UNK] [UNK] [end]\n",
      "although the number of new cases in myanmar has declined over the last years there were cases in and cases in according to rangoon general hospital. [start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "sorry world sorry syria we chinese have an evil government michael anti on twitter. [start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [end]\n",
      "Once again. [start] [UNK] [end]\n",
      "these images illustrate how litter is destroying myanmar s famous landmarks global voices. [start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [end]\n",
      "it all ended well when the cops decided to compare our id numbers they let me out asking by way of good bye turkish boyfriend yes. [start] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [end]\n",
      "What is the meaning of this word? [start] [UNK] [UNK] [UNK] [UNK] [end]\n",
      "I know your brother very well. [start] [UNK] [UNK] [end]\n",
      "sudan potassium bromide and witchcraft global voices. [start] [UNK] [UNK] [UNK] [UNK] [UNK] الاصوات الاصوات العالمية [end]\n",
      "sung hee myoung stressed. [start] [UNK] [UNK] [end]\n",
      "and med islem bouazizi reports ar. [start] [UNK] [UNK] [UNK] [UNK] [end]\n"
     ]
    }
   ],
   "source": [
    "ar_vocab = ar_vectorization.get_vocabulary()\n",
    "ar_index_lookup = dict(zip(range(len(ar_vocab)), ar_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = ar_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = ar_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(30):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    translated = decode_sequence(input_sentence)\n",
    "    print(input_sentence, translated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
