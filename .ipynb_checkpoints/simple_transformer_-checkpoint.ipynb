{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0R53kjrYGpSc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0R53kjrYGpSc",
    "outputId": "e120dfc2-3129-4b72-a9b3-08d54ef307b5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Arabic-English-Translation-Transformers'...\n",
      "remote: Enumerating objects: 8, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 8 (delta 0), reused 8 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (8/8), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/moaaztaha/Arabic-English-Translation-Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e9e97fa1",
   "metadata": {
    "id": "e9e97fa1"
   },
   "outputs": [],
   "source": [
    "# modules\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1710411f",
   "metadata": {
    "id": "1710411f"
   },
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1RNDMX9cizGW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "1RNDMX9cizGW",
    "outputId": "24aaab3e-5b5f-4e8b-c250-875175dd5592"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>ar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>مرحبًا.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>اركض!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Help!</td>\n",
       "      <td>النجدة!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jump!</td>\n",
       "      <td>اقفز!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop!</td>\n",
       "      <td>قف!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eng       ar\n",
       "0    Hi.  مرحبًا.\n",
       "1   Run!    اركض!\n",
       "2  Help!  النجدة!\n",
       "3  Jump!    اقفز!\n",
       "4  Stop!      قف!"
      ]
     },
     "execution_count": 253,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/content/Arabic-English-Translation-Transformers/ara_eng.txt\",delimiter=\"\\t\",names=[\"eng\",\"ar\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "m4aku8mEi7Xg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4aku8mEi7Xg",
    "outputId": "034d56b3-e97d-49ec-8032-8cebc912f63a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big\n",
      "big\n",
      "big\n",
      "big\n",
      "big\n"
     ]
    }
   ],
   "source": [
    "for i in range(df.shape[0]):\n",
    "  if len(df.eng.iloc[-i].split()) > 150:\n",
    "    print(\"big\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "be905b2c",
   "metadata": {
    "id": "be905b2c"
   },
   "outputs": [],
   "source": [
    "text_pairs = []\n",
    "for idx, row in df.iterrows():\n",
    "    eng, ar = row['eng'], row['ar']\n",
    "    ar = \"[start] \" + ar + \" [end]\"\n",
    "    text_pairs.append((eng, ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "296e4594",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "296e4594",
    "outputId": "c9f1bc2c-9acb-409b-f699-c8caec75f538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('during the closing session of the new media workshop i led recently in alexandria egypt practically everybody paid tribute to shahinaz abdelsalam better known in the blogosphere as wahda masrya an egyptian girl the lone alexandria native and one of the few experienced bloggers among the group shahinaz became for most of the participants a symbol of courage and deep commitment to the cause of human rights and of freedom expression.', '[start] خلال الجلسة النهايية من ورشة الاعلام الجديدة التي نظمتها في الاسكندرية مصر عمد الجميع للتعبير عن تقديرهم لشهيناز عبد السلام المعروفة ب واحدة مصرية عربي في عالم المدونات تلك الفتاة الوحيدة المتاصلة من الاسكندرية ومن بين قلة من المدونين المصريين المخضرمين في المجموعة باتت شاهيناز بالنسبة للعديد من المشاركين في الورشة رمزا للشجاعة والاخلاص لقضيتي حقوق الانسان وحرية التعبير [end]')\n",
      "('He is a naughty boy.', '[start] هو ولد مشاغب. [end]')\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c1283f6f",
   "metadata": {
    "id": "c1283f6f"
   },
   "outputs": [],
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) -  num_val_samples\n",
    "train_pairs = text_pairs[: num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples: num_train_samples + num_val_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a7a1f8cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7a1f8cd",
    "outputId": "9ac7d124-79e8-48d2-c149-de8983a66d8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24638 total pairs\n",
      "20943 training pairs\n",
      "3695 validation pairs\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f6d84e",
   "metadata": {
    "id": "d5f6d84e"
   },
   "source": [
    "#### Vectorizing the text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "487ed66f",
   "metadata": {
    "id": "487ed66f"
   },
   "outputs": [],
   "source": [
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "\n",
    "vocab_size = 20000\n",
    "sequence_length = 150\n",
    "batch_size = 128\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    return tf.strings.regex_replace(input_string, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "eng_vectorization = TextVectorization(\n",
    "            max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_length)\n",
    "\n",
    "ar_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization)\n",
    "\n",
    "eng_texts = [pair[0] for pair in text_pairs]\n",
    "ar_texts = [pair[1] for pair in text_pairs]\n",
    "eng_vectorization.adapt(eng_texts)\n",
    "ar_vectorization.adapt(ar_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "V5qiqjOWdVz1",
   "metadata": {
    "id": "V5qiqjOWdVz1"
   },
   "outputs": [],
   "source": [
    "def format_dataset(eng, ar):\n",
    "    eng = eng_vectorization(eng)\n",
    "    ar = ar_vectorization(ar)\n",
    "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": ar[:, :-1],}, ar[:, 1:])\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, ar_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    ar_texts = list(ar_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ar_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "7a3ed140",
   "metadata": {
    "id": "7a3ed140"
   },
   "outputs": [],
   "source": [
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3902789f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3902789f",
    "outputId": "790645ce-035f-46c8-88ca-ab7397b19ce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (128, 150)\n",
      "inputs[\"decoder_inputs\"].shape: (128, 150)\n",
      "targets.shape: (128, 150)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa0936c",
   "metadata": {
    "id": "4fa0936c"
   },
   "source": [
    "### Building the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b3baf452",
   "metadata": {
    "id": "b3baf452"
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "      config = super().get_config().copy()\n",
    "      config.update({\n",
    "          'embed_dim': self.embed_dim,\n",
    "          'dense_dim': self.dense_dim,\n",
    "          'num_heads': self.num_heads,\n",
    "      })\n",
    "      return config\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "      \n",
    "    def get_config(self):\n",
    "\n",
    "      config = super().get_config().copy()\n",
    "      config.update({\n",
    "      'sequence_length': self.sequence_length,\n",
    "      'vocab_size': self.vocab_size,\n",
    "      'embed_dim': self.embed_dim,\n",
    "      })\n",
    "      return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "      config = super().get_config().copy()\n",
    "      config.update({\n",
    "      'embed_dim': self.embed_dim,\n",
    "      'latent_dim': self.latent_dim,\n",
    "      'num_heads': self.num_heads,\n",
    "      })\n",
    "      return config\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "04c57e1e",
   "metadata": {
    "id": "04c57e1e"
   },
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "vt9sp6Yrb4pE",
   "metadata": {
    "id": "vt9sp6Yrb4pE"
   },
   "outputs": [],
   "source": [
    "googledrive_path = '/content/drive/MyDrive/Transformers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "wqmaEQ94kyB9",
   "metadata": {
    "id": "wqmaEQ94kyB9"
   },
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "early_stopping_cb = callbacks.EarlyStopping(monitor='val_accuracy', patience=4, verbose=True)\n",
    "checkpoint_cb = callbacks.ModelCheckpoint(googledrive_path+'model.h5', monitor='val_accuracy', verbose=True, save_best_only=True)\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=googledrive_path+\"logs\")\n",
    "cbs = [early_stopping_cb, checkpoint_cb, tensorboard_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "H50DkdfyLyqt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H50DkdfyLyqt",
    "outputId": "4fdc315d-03ba-4cbf-f53a-9237360bc76a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positional_embedding_24 (Positi (None, None, 256)    5158400     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_12 (Transfo (None, None, 256)    3155456     positional_embedding_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "model_25 (Functional)           (None, None, 20000)  15557920    decoder_inputs[0][0]             \n",
      "                                                                 transformer_encoder_12[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 23,871,776\n",
      "Trainable params: 23,871,776\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "164/164 [==============================] - 182s 915ms/step - loss: 0.7902 - accuracy: 0.1894 - val_loss: 0.7280 - val_accuracy: 0.2264\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.22635, saving model to /content/drive/MyDrive/Transformers/model.h5\n",
      "Epoch 2/30\n",
      "164/164 [==============================] - 148s 905ms/step - loss: 0.6871 - accuracy: 0.2444 - val_loss: 0.6861 - val_accuracy: 0.2434\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.22635 to 0.24343, saving model to /content/drive/MyDrive/Transformers/model.h5\n",
      "Epoch 3/30\n",
      "164/164 [==============================] - 148s 905ms/step - loss: 0.6205 - accuracy: 0.2733 - val_loss: 0.6646 - val_accuracy: 0.2637\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.24343 to 0.26371, saving model to /content/drive/MyDrive/Transformers/model.h5\n",
      "Epoch 4/30\n",
      "164/164 [==============================] - 148s 900ms/step - loss: 0.5644 - accuracy: 0.2970 - val_loss: 0.6503 - val_accuracy: 0.2629\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.26371\n",
      "Epoch 5/30\n",
      "164/164 [==============================] - 148s 905ms/step - loss: 0.5132 - accuracy: 0.3204 - val_loss: 0.6527 - val_accuracy: 0.2549\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.26371\n",
      "Epoch 6/30\n",
      "164/164 [==============================] - 149s 906ms/step - loss: 0.4668 - accuracy: 0.3462 - val_loss: 0.6591 - val_accuracy: 0.2637\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.26371 to 0.26374, saving model to /content/drive/MyDrive/Transformers/model.h5\n",
      "Epoch 7/30\n",
      "164/164 [==============================] - 148s 900ms/step - loss: 0.4253 - accuracy: 0.3737 - val_loss: 0.6717 - val_accuracy: 0.2629\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.26374\n",
      "Epoch 8/30\n",
      "164/164 [==============================] - 148s 901ms/step - loss: 0.3890 - accuracy: 0.4029 - val_loss: 0.6878 - val_accuracy: 0.2569\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.26374\n",
      "Epoch 9/30\n",
      "164/164 [==============================] - 148s 903ms/step - loss: 0.3548 - accuracy: 0.4346 - val_loss: 0.7166 - val_accuracy: 0.2657\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.26374 to 0.26569, saving model to /content/drive/MyDrive/Transformers/model.h5\n",
      "Epoch 10/30\n",
      "164/164 [==============================] - 148s 905ms/step - loss: 0.3243 - accuracy: 0.4662 - val_loss: 0.7105 - val_accuracy: 0.2581\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.26569\n",
      "Epoch 11/30\n",
      "164/164 [==============================] - 148s 905ms/step - loss: 0.2977 - accuracy: 0.4961 - val_loss: 0.7279 - val_accuracy: 0.2538\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.26569\n",
      "Epoch 12/30\n",
      "164/164 [==============================] - 147s 899ms/step - loss: 0.2695 - accuracy: 0.5300 - val_loss: 0.7478 - val_accuracy: 0.2531\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.26569\n",
      "Epoch 13/30\n",
      "164/164 [==============================] - 148s 905ms/step - loss: 0.2464 - accuracy: 0.5602 - val_loss: 0.7707 - val_accuracy: 0.2472\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.26569\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f46d3271bd0>"
      ]
     },
     "execution_count": 277,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 30  # This should be at least 30 for convergence\n",
    "\n",
    "transformer.summary()\n",
    "transformer.compile(\n",
    "    \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "8447490b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8447490b",
    "outputId": "95a7a075-13d9-4500-a08b-49be10b48c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "لماذا يسعى الاوربيون الى طريق بحري الى الهند؟ \n",
      " [start] why are not going to leave their seats to a blood [end]\n",
      "**************************************************\n",
      "دمتري اولتشانسكي الصورة من فيسبوك \n",
      " [start] [UNK] on flickr photo by flickr user [end]\n",
      "**************************************************\n",
      "ولد فريق كومابا يوم من اغسطس اب بعد الحفلة السنوية للمنهج التعليمي مقدمة للموسيقى الفنزويلية وامريكا اللاتينية وخرج الفريق من بين الموسيقيين من هذا الفصل وايضا من هولاء الراغبين في لعب الموسيقى الفنزويلية طوال العام جاءت فكرة تدريس الموسيقى الفنزويلية في جامعة يابانية بعد سنة من عمل الاستاذ اشيباشي على نشر الموسيقى الفنزويلية بعيدا عن منشاها الاصلي \n",
      " [start] a mother of the girl from august after the party went to the party of the brazilian artists from his\n",
      "**************************************************\n",
      "أنا أتتطلع لحفلة عيد القديسيين خاصتك. \n",
      " [start] im looking forward to the christmas dinner [end]\n",
      "**************************************************\n",
      "بوليفيا تسمية مدون لرياسة المحكمة الانتخابية الوطنية الاصوات العالمية \n",
      " [start] bolivia new blogger for an election national electoral court global voices [end]\n",
      "**************************************************\n",
      "في شريط فيديو نشره الصحافي مارسيل فورتا على يوتيوب عضو الكونجرس ايفان فالنتي من حزب الاشتراكية والحرية وضح احتجاج السكان الاصليين كوسيلة لضمان الحقوق الدستورية \n",
      " [start] in a video posted a video of the indigenous group of protesters posted by protesters posted on the party of\n",
      "**************************************************\n",
      "وبحلول السابع من ايار مايو من عام اندلعت المواجهات في بيروت وجبل لبنان عقب رد حزب الله وحلفايه على ذلك بهجمات مسلحة على مكاتب تيار المستقبل والحزب التقدمي الاشتراكي وقتل حوالي مية شخص من بينهم مدنيون ما بين السابع من ايار والرابع عشر منه \n",
      " [start] the th of the may from may of the end of the palestinian revolution and party of the party headquarters\n",
      "**************************************************\n",
      "استمتع بوقتك. \n",
      " [start] i know him [end]\n",
      "**************************************************\n",
      "الرام جيجا بايت \n",
      " [start] united nations has been stolen [end]\n",
      "**************************************************\n",
      "المدون جوشوا فاوست ينشر تقرير عن قطار غامض مملوء بمادة السيزيوم ومتجه الى ايران تم ايقافه على الحدود القرغيزية مع اوزبكستان لكن المسوولين القرغيز انتظروا اكثر من اسبوع قبل الكشف عن الحادثة \n",
      " [start] [UNK] [UNK] from the report on the train has been [UNK] train and iran to the end of iran s\n",
      "**************************************************\n",
      "أنت مُسامح. \n",
      " [start] you are a good cook [end]\n",
      "**************************************************\n",
      "هل أنت جاهز؟ \n",
      " [start] are you ready [end]\n",
      "**************************************************\n",
      "ان القسم العلوي يمثل ساحة تيانانمن المزينة بالعام فيظهر تاريخ الاحداث ومكانها على حد سواء بينما تشكل ساحة تيانانمن المضاف اليها خطان عموديان العلامة الصينية للرقم ستة وفوق ذلك يشكل القسم السفلي من الصورة العلامة بمعنى الرقم اربعة فتظهر في الصورة الكاملة العلامة الصينية القديمة ومن سخرية القدر ان تحمل هذه العلامة في استخدامها الراهن على الانترنت معاني حزين و كييب و مغلظ بينما يشير معناه الاصلي الى الشيء اللامع لذلك تنقل هذه الكنزة الرسالة التالية بالرغم من فشل الحركة الاصلية على الرابع من حزيران فانها قد باتت رمزا للجيل الجديد الذي يجتهد من اجل مستقبل لامع وديموقراطي وهذه الحركة مهمة كثيرا بالنسبة لتطوير الديموقراطية الصينية \n",
      " [start] the story of the atomic number of the year old [UNK] and [UNK] of events in the history the [UNK]\n",
      "**************************************************\n",
      "هل أنت ماهر في لعب التنس؟ \n",
      " [start] do you really enjoyed at tennis [end]\n",
      "**************************************************\n",
      "قام مبنى اتش اس بي سي مبنى مالي بارز في مركز هونج كونج بتغيير الوان اضاءته لتصبح الوان قوس قزح اعلانا لدعمه العاملين المثليين المثليات مزدوجي الميول الجنسية ومغايري الجنس المقال من هونج رونج \n",
      " [start] the building of [UNK] [UNK] and three years of mali s largest city s euromaidan protests in the black mauritanians\n",
      "**************************************************\n",
      "وبامكانكم ايضا ارسال اسيلتكم الينا على العنوان التالي \n",
      " [start] you can also help us on the address the next day [end]\n",
      "**************************************************\n",
      "ايران التدوين ضد رهاب المثلية الجنسية الاصوات العالمية \n",
      " [start] iran blogging against blogging against the global voices [end]\n",
      "**************************************************\n",
      "علينا تكرار هذا غدا. \n",
      " [start] we have to pay back tomorrow [end]\n",
      "**************************************************\n",
      "أرني كيف تعمل. \n",
      " [start] show how to the work [end]\n",
      "**************************************************\n",
      "عموماً ، مدّخرات الأفراد في اِزدياد. \n",
      " [start] the wild elephant comes with a teacher [end]\n",
      "**************************************************\n",
      "كان لدى السيدة قصة تستحق المتابعة والنشر ما جذبني اليها كان انها لم تخفي اصابتها بمرض الايدز واعلان ذلك علنا في في مالاوي كان تقريبا من المحرمات الا انها تحدت جميع الصعاب حتى عنجما لم يكن هناك ادوية للايدز بعد ثمان سنوات لا زال من الصعب التخلص من ذلك الصمت الذهبي حول الايدز في مالاوي \n",
      " [start] the new year old girl is worth fighting for the latest case you don t have no longer the same\n",
      "**************************************************\n",
      "وبالفعل بدا بعض مستخدمي موقع فيكونتاكت ملاحظة خدمات التذكير لكن هناك بعض النساء اللواتي لا تتقبلن فكرة انفاق المال على اعلانات الانترنت التي تهدف لتحسين علاقاتهم فمثلا كتبت الينا اوشكوفا على صفحتها في موقع فيكونتاكت تعليقا على موقع اريد زهورا انا افضل ان اشتري لنفسي الزهور على ان انفق اموالي على هذه الخدمة السخيفة \n",
      " [start] i started some netizens from there are a note but it s facebook and the women s an idea to\n",
      "**************************************************\n",
      "اما في حالة رغبتك في الانضمام الينا لكن لا تستطيع ما زالت هناك فرصة لمتابعتنا عبر البث الحي لبعض فقرات برنامجنا يومي و من يوليو تموز كما يمكنك متابعة المقالات التي يكتبها افراد مجتمع الاصوات العالمية ومتحدثينا من خلال موقع الموتمر ومتابعتنا عبر تويتر وفيسبوك \n",
      " [start] the global voices is a new constitution but not been using the past a chance of our chance in their\n",
      "**************************************************\n",
      "لن ينتهي ذلك أبداً. \n",
      " [start] we wont happen [end]\n",
      "**************************************************\n",
      "الدرس الأول سهل. \n",
      " [start] this is easy to be a book [end]\n",
      "**************************************************\n",
      "ما مجال عمل خالتك؟ \n",
      " [start] what the work of the job [end]\n",
      "**************************************************\n",
      "شيد الجسر على يد الروم. \n",
      " [start] the bridge is the hand for a hand in the bridge is the bridge is the bridge at the boat\n",
      "**************************************************\n",
      "لمَ يحدث هذا ثانيةً؟ \n",
      " [start] why is this is that [end]\n",
      "**************************************************\n",
      "عبر مستخدمو الشبكة التايوانيون عن مخاوفهم بخصوص نظام الاغاثة وانذار الكوارث خاصتهم فيما كانت التحديثات الحية عن زلزال اليابان والتسونامي تتوالى على موقع تويتر ونورد فيما يلي مختارات من الاستجابات وردود الفعل الفورية على الحدث والتي ابداها مستخدمو الموقع \n",
      " [start] through the social media platform you know about the national stadium in russia s help them as well as the\n",
      "**************************************************\n",
      "عندما قامت مجموعة من المتظاهرين المصريين باقتحام المقر الرييسي لمبنى امن الدولة في مختلف المدن المصرية لم يكن هدفها اظهار حنقها وغضبها على الموسسة نفسها التي لاتحظى باي شعبية في الشارع المصري لارتباطها بنظام مبارك السابق وانما من اجل اعادة كتابة التاريخ \n",
      " [start] when the group of protesters are the army of the rambo syndrom the state security forces of the arab cities\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "ar_vocab = ar_vectorization.get_vocabulary()\n",
    "ar_index_lookup = dict(zip(range(len(ar_vocab)), ar_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = ar_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = ar_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in val_pairs]\n",
    "for _ in range(30):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    translated = decode_sequence(input_sentence)\n",
    "    print(input_sentence, '\\n', translated)\n",
    "    print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HtSYN8hAG3Zl",
   "metadata": {
    "id": "HtSYN8hAG3Zl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "simple transformer .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
