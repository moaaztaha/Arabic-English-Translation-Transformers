{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "simple transformer_50k.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R53kjrYGpSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a1621ae-1a8d-4f13-93ee-dcd904dbbd01"
      },
      "source": [
        "!git clone https://github.com/moaaztaha/Arabic-English-Translation-Transformers"
      ],
      "id": "0R53kjrYGpSc",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Arabic-English-Translation-Transformers'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 24 (delta 0), reused 24 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9e97fa1"
      },
      "source": [
        "# modules\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "id": "e9e97fa1",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1710411f"
      },
      "source": [
        "### Data Preprocessing "
      ],
      "id": "1710411f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RNDMX9cizGW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a5babae5-fd8f-4ee1-f5be-f0ac0e2250ed"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/Arabic-English-Translation-Transformers/ara_eng.txt\",delimiter=\"\\t\",names=[\"eng\",\"ar\"])\n",
        "df.head()"
      ],
      "id": "1RNDMX9cizGW",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>ar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>مرحبًا.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>اركض!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Help!</td>\n",
              "      <td>النجدة!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jump!</td>\n",
              "      <td>اقفز!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>قف!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     eng       ar\n",
              "0    Hi.  مرحبًا.\n",
              "1   Run!    اركض!\n",
              "2  Help!  النجدة!\n",
              "3  Jump!    اقفز!\n",
              "4  Stop!      قف!"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4aku8mEi7Xg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f3cf83-7e4f-46c2-c60a-2339a8b0923d"
      },
      "source": [
        "for i in range(df.shape[0]):\n",
        "  if len(df.eng.iloc[-i].split()) > 150:\n",
        "    print(\"big\")"
      ],
      "id": "m4aku8mEi7Xg",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "big\n",
            "big\n",
            "big\n",
            "big\n",
            "big\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be905b2c"
      },
      "source": [
        "text_pairs = []\n",
        "for idx, row in df.iterrows():\n",
        "    eng, ar = row['eng'], row['ar']\n",
        "    ar = \"[start] \" + ar + \" [end]\"\n",
        "    text_pairs.append((eng, ar))"
      ],
      "id": "be905b2c",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "296e4594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83626337-2eef-4dfd-91c3-77b5b13455ec"
      },
      "source": [
        "for _ in range(2):\n",
        "    print(random.choice(text_pairs))"
      ],
      "id": "296e4594",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('since the government of kuwait has ramped up efforts to control online speech and activity according to human rights watch twitter user musab shamsah was sentenced to five years in prison for a tweet that commented on theological differences between sunni and shia muslims.', '[start] منذ عام ٢٠١٢ لا تالو الحكومة الكويتية جهدا في سبيل التحكم في الخطاب والنشاط الالكتروني نشرت منظمة هيومان رايتس ووتش خبرا عن حبس المغرد مصعب شمساه خمس سنوات على تغريدة مسيية اثناء نقاش بين سنة وشيعة [end]')\n",
            "('His help is indispensable to us.', '[start] لا غِنى لنا عن مساعدته. [end]')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1283f6f"
      },
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) -  num_val_samples\n",
        "train_pairs = text_pairs[: num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples: num_train_samples + num_val_samples]"
      ],
      "id": "c1283f6f",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7a1f8cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad71718-9a80-400a-de91-62478ce457d9"
      },
      "source": [
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")"
      ],
      "id": "a7a1f8cd",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24638 total pairs\n",
            "20943 training pairs\n",
            "3695 validation pairs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5f6d84e"
      },
      "source": [
        "#### Vectorizing the text data "
      ],
      "id": "d5f6d84e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "487ed66f"
      },
      "source": [
        "strip_chars = string.punctuation\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "\n",
        "vocab_size = 50000\n",
        "sequence_length = 150\n",
        "batch_size = 64\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    return tf.strings.regex_replace(input_string, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "            max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_length)\n",
        "\n",
        "ar_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization)\n",
        "\n",
        "eng_texts = [pair[0] for pair in text_pairs]\n",
        "ar_texts = [pair[1] for pair in text_pairs]\n",
        "eng_vectorization.adapt(eng_texts)\n",
        "ar_vectorization.adapt(ar_texts)"
      ],
      "id": "487ed66f",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5qiqjOWdVz1"
      },
      "source": [
        "def format_dataset(eng, ar):\n",
        "    eng = eng_vectorization(eng)\n",
        "    ar = ar_vectorization(ar)\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": ar[:, :-1],}, ar[:, 1:])\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, ar_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    ar_texts = list(ar_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ar_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()"
      ],
      "id": "V5qiqjOWdVz1",
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a3ed140"
      },
      "source": [
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "id": "7a3ed140",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3902789f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b08340-1263-4e82-e683-1f1f1efbcf8d"
      },
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "id": "3902789f",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 150)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 150)\n",
            "targets.shape: (64, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fa0936c"
      },
      "source": [
        "### Building the Model "
      ],
      "id": "4fa0936c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3baf452"
      },
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "      config = super().get_config().copy()\n",
        "      config.update({\n",
        "          'embed_dim': self.embed_dim,\n",
        "          'dense_dim': self.dense_dim,\n",
        "          'num_heads': self.num_heads,\n",
        "      })\n",
        "      return config\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "      \n",
        "    def get_config(self):\n",
        "\n",
        "      config = super().get_config().copy()\n",
        "      config.update({\n",
        "      'sequence_length': self.sequence_length,\n",
        "      'vocab_size': self.vocab_size,\n",
        "      'embed_dim': self.embed_dim,\n",
        "      })\n",
        "      return config\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "      config = super().get_config().copy()\n",
        "      config.update({\n",
        "      'embed_dim': self.embed_dim,\n",
        "      'latent_dim': self.latent_dim,\n",
        "      'num_heads': self.num_heads,\n",
        "      })\n",
        "      return config\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ],
      "id": "b3baf452",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04c57e1e"
      },
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "id": "04c57e1e",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt9sp6Yrb4pE"
      },
      "source": [
        "googledrive_path = '/content/drive/MyDrive/Transformers/voc50k/'"
      ],
      "id": "vt9sp6Yrb4pE",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqmaEQ94kyB9"
      },
      "source": [
        "from keras import callbacks\n",
        "early_stopping_cb = callbacks.EarlyStopping(monitor='val_accuracy', patience=4, verbose=True)\n",
        "checkpoint_cb = callbacks.ModelCheckpoint(googledrive_path+'weights_rmsprop.ckpt', monitor='val_accuracy', save_weights_only=True,verbose=True, save_best_only=True)\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=googledrive_path+\"logs\")\n",
        "cbs = [early_stopping_cb, checkpoint_cb, tensorboard_callback]"
      ],
      "id": "wqmaEQ94kyB9",
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H50DkdfyLyqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a21d41-f1f4-4eb0-b11d-d3fcb7663be0"
      },
      "source": [
        "epochs = 30  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=cbs)"
      ],
      "id": "H50DkdfyLyqt",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "positional_embedding_10 (Positi (None, None, 256)    12838400    encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder_5 (Transfor (None, None, 256)    3155456     positional_embedding_10[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "model_11 (Functional)           (None, None, 50000)  30947920    decoder_inputs[0][0]             \n",
            "                                                                 transformer_encoder_5[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 46,941,776\n",
            "Trainable params: 46,941,776\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "328/328 [==============================] - 239s 720ms/step - loss: 0.9206 - accuracy: 0.1172 - val_loss: 0.8773 - val_accuracy: 0.1399\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.13991, saving model to /content/drive/MyDrive/Transformers/voc50k/weights_rmsprop.ckpt\n",
            "Epoch 2/30\n",
            "328/328 [==============================] - 237s 722ms/step - loss: 0.8780 - accuracy: 0.1442 - val_loss: 0.8596 - val_accuracy: 0.1524\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.13991 to 0.15238, saving model to /content/drive/MyDrive/Transformers/voc50k/weights_rmsprop.ckpt\n",
            "Epoch 3/30\n",
            "328/328 [==============================] - 236s 721ms/step - loss: 0.8554 - accuracy: 0.1610 - val_loss: 0.8367 - val_accuracy: 0.1734\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.15238 to 0.17342, saving model to /content/drive/MyDrive/Transformers/voc50k/weights_rmsprop.ckpt\n",
            "Epoch 4/30\n",
            "328/328 [==============================] - 237s 723ms/step - loss: 0.8360 - accuracy: 0.1746 - val_loss: 0.8265 - val_accuracy: 0.1779\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.17342 to 0.17788, saving model to /content/drive/MyDrive/Transformers/voc50k/weights_rmsprop.ckpt\n",
            "Epoch 5/30\n",
            "328/328 [==============================] - 237s 723ms/step - loss: 0.8185 - accuracy: 0.1872 - val_loss: 0.8238 - val_accuracy: 0.1867\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.17788 to 0.18671, saving model to /content/drive/MyDrive/Transformers/voc50k/weights_rmsprop.ckpt\n",
            "Epoch 6/30\n",
            "328/328 [==============================] - 237s 723ms/step - loss: 0.8031 - accuracy: 0.1991 - val_loss: 0.8161 - val_accuracy: 0.1933\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.18671 to 0.19330, saving model to /content/drive/MyDrive/Transformers/voc50k/weights_rmsprop.ckpt\n",
            "Epoch 7/30\n",
            "328/328 [==============================] - 238s 726ms/step - loss: 0.7885 - accuracy: 0.2098 - val_loss: 0.8158 - val_accuracy: 0.1966\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.19330 to 0.19657, saving model to /content/drive/MyDrive/Transformers/voc50k/weights_rmsprop.ckpt\n",
            "Epoch 8/30\n",
            "328/328 [==============================] - 238s 727ms/step - loss: 0.7757 - accuracy: 0.2190 - val_loss: 0.8083 - val_accuracy: 0.1955\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.19657\n",
            "Epoch 9/30\n",
            "328/328 [==============================] - 238s 725ms/step - loss: 0.7644 - accuracy: 0.2275 - val_loss: 0.8099 - val_accuracy: 0.2015\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.19657 to 0.20153, saving model to /content/drive/MyDrive/Transformers/voc50k/weights_rmsprop.ckpt\n",
            "Epoch 10/30\n",
            "328/328 [==============================] - 237s 723ms/step - loss: 0.7540 - accuracy: 0.2360 - val_loss: 0.8107 - val_accuracy: 0.2047\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.20153 to 0.20470, saving model to /content/drive/MyDrive/Transformers/voc50k/weights_rmsprop.ckpt\n",
            "Epoch 11/30\n",
            "328/328 [==============================] - 238s 727ms/step - loss: 0.7445 - accuracy: 0.2439 - val_loss: 0.8090 - val_accuracy: 0.2067\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.20470 to 0.20668, saving model to /content/drive/MyDrive/Transformers/voc50k/weights_rmsprop.ckpt\n",
            "Epoch 12/30\n",
            "328/328 [==============================] - 236s 719ms/step - loss: 0.7349 - accuracy: 0.2516 - val_loss: 0.8111 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.20668\n",
            "Epoch 13/30\n",
            "328/328 [==============================] - 239s 729ms/step - loss: 0.7263 - accuracy: 0.2593 - val_loss: 0.8176 - val_accuracy: 0.2073\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.20668 to 0.20730, saving model to /content/drive/MyDrive/Transformers/voc50k/weights_rmsprop.ckpt\n",
            "Epoch 14/30\n",
            "328/328 [==============================] - 240s 731ms/step - loss: 0.7172 - accuracy: 0.2668 - val_loss: 0.8159 - val_accuracy: 0.2058\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.20730\n",
            "Epoch 15/30\n",
            "328/328 [==============================] - 237s 724ms/step - loss: 0.7092 - accuracy: 0.2742 - val_loss: 0.8241 - val_accuracy: 0.2066\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.20730\n",
            "Epoch 16/30\n",
            "328/328 [==============================] - 237s 724ms/step - loss: 0.7001 - accuracy: 0.2817 - val_loss: 0.8172 - val_accuracy: 0.2114\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.20730 to 0.21144, saving model to /content/drive/MyDrive/Transformers/voc50k/weights_rmsprop.ckpt\n",
            "Epoch 17/30\n",
            "328/328 [==============================] - 238s 725ms/step - loss: 0.6918 - accuracy: 0.2897 - val_loss: 0.8302 - val_accuracy: 0.1990\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.21144\n",
            "Epoch 18/30\n",
            "328/328 [==============================] - 239s 728ms/step - loss: 0.6839 - accuracy: 0.2979 - val_loss: 0.8193 - val_accuracy: 0.2035\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.21144\n",
            "Epoch 19/30\n",
            "328/328 [==============================] - 238s 726ms/step - loss: 0.6767 - accuracy: 0.3061 - val_loss: 0.8297 - val_accuracy: 0.2073\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.21144\n",
            "Epoch 20/30\n",
            "328/328 [==============================] - 239s 729ms/step - loss: 0.6708 - accuracy: 0.3136 - val_loss: 0.8208 - val_accuracy: 0.2107\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.21144\n",
            "Epoch 00020: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f88a9f80cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Qvebl8FHsG",
        "outputId": "0049bdd3-8796-4d58-c8bc-6285a4f28b41"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(googledrive_path)\n",
        "transformer.load_weights(latest)"
      ],
      "id": "j5Qvebl8FHsG",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f88bc91b350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8447490b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a7bd6d-dafe-487b-c475-682157cd42dc"
      },
      "source": [
        "ar_vocab = ar_vectorization.get_vocabulary()\n",
        "ar_index_lookup = dict(zip(range(len(ar_vocab)), ar_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = ar_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = ar_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in val_pairs]\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts[:30])\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(input_sentence, '\\n', translated)\n",
        "    print('*'*50)"
      ],
      "id": "8447490b",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the following two pictures were sent to blogger anthala. \n",
            " [start] [UNK] [UNK] بعض الصور من مدونة [end]\n",
            "**************************************************\n",
            "My grandfather comes from Osaka. \n",
            " [start] سوف [UNK] [UNK] على [end]\n",
            "**************************************************\n",
            "suara blogger indonesia explains how the indonesian government blocks internet content in the country through the help of local internet service providers indonesia has one of the most active social media communities in the world. \n",
            " [start] المدون المصري محمد انكليزي من اجل حرية التعبير في موقع [UNK] في مجال الانترنت في مجال حقوق الانسان في مجال\n",
            "**************************************************\n",
            "bellavista santiago chile photo by patricia vargas used with permission. \n",
            " [start] ترينيداد دي اوكرانيا تصوير مستخدمة باذن [end]\n",
            "**************************************************\n",
            "recently a new book documenting the ancient art of henna was released the book entitled moor a henna atlas of morocco contains illustrations and photographs of the beautiful moroccan version of the art form a sneak peek. \n",
            " [start] المدون انكليزي من هنا هو فيلم وثايقي على يوتيوب [end]\n",
            "**************************************************\n",
            "Do you want a drink? \n",
            " [start] هل تعرف أنه أنت [UNK] [end]\n",
            "**************************************************\n",
            "the following video shows the brave women of taiz whose city was shelled by saleh s forces in the evening marching the very next day despite the rain to condemn the violence and demand the trial of saleh and his family video posted by mohammednaruto. \n",
            " [start] نشر بعض الصور من اجل [UNK] في مدينة [UNK] [UNK] [UNK] [UNK] عن بعض الناس الذين لم يكن هناك بعض\n",
            "**************************************************\n",
            "the following video shows the brave women of taiz whose city was shelled by saleh s forces in the evening marching the very next day despite the rain to condemn the violence and demand the trial of saleh and his family video posted by mohammednaruto. \n",
            " [start] نشر بعض الصور من اجل [UNK] في مدينة [UNK] [UNK] [UNK] [UNK] عن بعض الناس الذين لم يكن هناك بعض\n",
            "**************************************************\n",
            "the impossible texting and driving test is part of a campaign to raise awareness to the dangers of texting using mobile devices while driving in belgium several young people doing their behind the wheel driving test were surprised to know there was a new test section requiring them to text while driving the dashboard cam tells the story of how these young people faced this new part of the test. \n",
            " [start] [UNK] [UNK] ايضا عن العالم هي مشروع الاعلام الاجتماعي في [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] على\n",
            "**************************************************\n",
            "It is dangerous to drive so fast. \n",
            " [start] لا تتحدث عن [UNK] [end]\n",
            "**************************************************\n",
            "recently a new book documenting the ancient art of henna was released the book entitled moor a henna atlas of morocco contains illustrations and photographs of the beautiful moroccan version of the art form a sneak peek. \n",
            " [start] المدون انكليزي من هنا هو فيلم وثايقي على يوتيوب [end]\n",
            "**************************************************\n",
            "the june incident in in beijing after the crackdown hong kong people hold annual candlelight vigil demanding the vindication of june. \n",
            " [start] قام الصحفي في جامعة [UNK] في الولايات المتحدة انكليزي الذي تم [UNK] في اغسطس اب في اغسطس اب [end]\n",
            "**************************************************\n",
            "the following two pictures were sent to blogger anthala. \n",
            " [start] [UNK] [UNK] بعض الصور من مدونة [end]\n",
            "**************************************************\n",
            "Let's check with an expert. \n",
            " [start] دعنا تعرف أنه يعرف عن العمل [end]\n",
            "**************************************************\n",
            "recently a new book documenting the ancient art of henna was released the book entitled moor a henna atlas of morocco contains illustrations and photographs of the beautiful moroccan version of the art form a sneak peek. \n",
            " [start] المدون انكليزي من هنا هو فيلم وثايقي على يوتيوب [end]\n",
            "**************************************************\n",
            "two bloggers have written about the foreign intervention and influence on the presidential election. \n",
            " [start] كتب المدون الفلسطيني هيثم صباح انكليزي عن شهر نوفمبر تشرين الثاني [end]\n",
            "**************************************************\n",
            "this conversation was moderated by nevin thompson global voices social media editor and japan editor. \n",
            " [start] هذه هي [UNK] على موقع الاصوات العالمية هو موقع اليابان [end]\n",
            "**************************************************\n",
            "Tom drove the car. \n",
            " [start] توم يعمل السيارة [end]\n",
            "**************************************************\n",
            "sovereigns of cyberspace. \n",
            " [start] قطر [end]\n",
            "**************************************************\n",
            "egyptian blogger arrested and prevented from covering a taxi drivers strike global voices. \n",
            " [start] المدون المصري محمد [UNK] الذي [UNK] في [UNK] الاصوات العالمية [end]\n",
            "**************************************************\n",
            "mr wu had this to say about the end of the games. \n",
            " [start] [UNK] أن هذه [UNK] [UNK] [UNK] [UNK] [end]\n",
            "**************************************************\n",
            "with that in mind eff together with global voices advocacy have created a set of questions to consider this list is by no means exhaustive but should offer a starting point from which bloggers can develop their own contingency plans. \n",
            " [start] مع ذلك [UNK] [UNK] منظمة غير حكومية في الاصوات العالمية قام من موقع [UNK] و [UNK] و [UNK] و و\n",
            "**************************************************\n",
            "It is dangerous to drive so fast. \n",
            " [start] لا تتحدث عن [UNK] [end]\n",
            "**************************************************\n",
            "He likes watching TV. \n",
            " [start] هو تحب [UNK] [end]\n",
            "**************************************************\n",
            "What is going on here? \n",
            " [start] ما الذي يحدث هنا؟ [end]\n",
            "**************************************************\n",
            "It is dangerous to drive so fast. \n",
            " [start] لا تتحدث عن [UNK] [end]\n",
            "**************************************************\n",
            "educacion viva live education has released the first of their videos challenging traditional education systems titled i don t believe in schools but i do believe in education in the subtitled video more than men and women read aloud a poem on the educational system and how it is different from what they believe education is. \n",
            " [start] مدونة تكتب عن [UNK] في فيديو عن كيفية استخدام العمل التي لا يمكن ان تكون هذه [UNK] في [UNK] في\n",
            "**************************************************\n",
            "Why is it that you're always late? \n",
            " [start] لماذا هو ذلك؟ [end]\n",
            "**************************************************\n",
            "educacion viva live education has released the first of their videos challenging traditional education systems titled i don t believe in schools but i do believe in education in the subtitled video more than men and women read aloud a poem on the educational system and how it is different from what they believe education is. \n",
            " [start] مدونة تكتب عن [UNK] في فيديو عن كيفية استخدام العمل التي لا يمكن ان تكون هذه [UNK] في [UNK] في\n",
            "**************************************************\n",
            "My grandfather comes from Osaka. \n",
            " [start] سوف [UNK] [UNK] على [end]\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iD1guTcL5zs",
        "outputId": "1203d45d-99d6-4ba6-81ce-5e5758ca4dd3"
      },
      "source": [
        "input_sentence = 'cold war'\n",
        "translated = decode_sequence(input_sentence)\n",
        "print(input_sentence, '\\n', translated)\n",
        "print('*'*50)"
      ],
      "id": "2iD1guTcL5zs",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cold war \n",
            " [start] الحياة الحرب [end]\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_QDHnhO1lW_"
      },
      "source": [
        ""
      ],
      "id": "D_QDHnhO1lW_",
      "execution_count": null,
      "outputs": []
    }
  ]
}